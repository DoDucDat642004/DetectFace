{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Data :\n",
    "#     +) https://www.kaggle.com/datasets/vfomenko/young-affectnet-hq\n",
    "#     +) https://www.kaggle.com/datasets/arnabkumarroy02/ferplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1. STANDARD LIBRARIES (Thư viện chuẩn Python)\n",
    "# ============================================================\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "from glob import glob\n",
    "from collections import Counter\n",
    "from io import BytesIO\n",
    "\n",
    "# ============================================================\n",
    "# 2. DATA SCIENCE & UTILITIES (Xử lý dữ liệu, ảnh, request)\n",
    "# ============================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Scikit-learn (Metrics & Model Selection)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# ============================================================\n",
    "# 3. PYTORCH & DEEP LEARNING\n",
    "# ============================================================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.amp as amp  # Mixed Precision Training\n",
    "\n",
    "# Data handling\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "# Torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "# Schedulers\n",
    "from torch.optim.lr_scheduler import LinearLR, CosineAnnealingLR, SequentialLR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1) CẤU HÌNH (CONFIG)\n",
    "# ============================================================\n",
    "\n",
    "# Danh sách các nhãn (class) hợp lệ\n",
    "VALID_CLASSES = [\"angry\", \"fear\", \"happy\", \"neutral\", \"sad\", \"surprise\"]\n",
    "\n",
    "# Bản đồ ánh xạ các nhãn khác nhau về nhãn chuẩn\n",
    "EMOTION_MAP = {\n",
    "    \"anger\": \"angry\",\n",
    "    \"disgust\": \"angry\",   # Gom 'ghê tởm' vào 'giận dữ'\n",
    "    \"contempt\": \"angry\",  # Gom 'khinh bỉ' vào 'giận dữ'\n",
    "    \"fear\": \"fear\",\n",
    "    \"happiness\": \"happy\",\n",
    "    \"sadness\": \"sad\",\n",
    "    \"surprise\": \"surprise\",\n",
    "    \"neutral\": \"neutral\",\n",
    "}\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2) LÀM SẠCH NHÃN (CLEAN LABELS)\n",
    "# ============================================================\n",
    "\n",
    "def clean_labels(df):\n",
    "    \"\"\"\n",
    "    Chuẩn hóa tên nhãn về chữ thường, xóa khoảng trắng thừa,\n",
    "    ánh xạ về tên chuẩn và lọc bỏ các nhãn không nằm trong VALID_CLASSES.\n",
    "    \"\"\"\n",
    "    df['label'] = (\n",
    "        df['label']\n",
    "        .str.lower()\n",
    "        .str.strip()\n",
    "        .replace({\n",
    "            'suprise': 'surprise',  # Sửa lỗi chính tả\n",
    "            'happiness': 'happy',\n",
    "            'sadness': 'sad',\n",
    "            'anger': 'angry',\n",
    "            'disgust': 'angry',\n",
    "            'contempt': 'angry',\n",
    "        })\n",
    "    )\n",
    "    # Chỉ giữ lại các dòng có nhãn nằm trong danh sách cho phép\n",
    "    return df[df['label'].isin(VALID_CLASSES)].reset_index(drop=True)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3) TẢI DỮ LIỆU (LOAD DATASET)\n",
    "# ============================================================\n",
    "\n",
    "def load_dataset(base_dir, exts=(\"jpg\", \"jpeg\", \"png\")):\n",
    "    \"\"\"\n",
    "    Quét thư mục để tìm ảnh. Tự động phát hiện cấu trúc thư mục.\n",
    "    Hỗ trợ cấu trúc: root/train/label/image.jpg hoặc root/label/image.jpg\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    # Kiểm tra xem thư mục gốc có sub-folder 'train'/'test'\n",
    "    has_subset = any(x in os.listdir(base_dir) for x in [\"train\", \"test\"])\n",
    "\n",
    "    folders = [\"train\", \"test\"] if has_subset else [\"\"]\n",
    "\n",
    "    for subset in folders:\n",
    "        subset_dir = os.path.join(base_dir, subset)\n",
    "        # Nếu thư mục không tồn tại thì bỏ qua\n",
    "        if not os.path.exists(subset_dir):\n",
    "            continue\n",
    "            \n",
    "        for label in os.listdir(subset_dir):\n",
    "            label_dir = os.path.join(subset_dir, label)\n",
    "            if not os.path.isdir(label_dir):\n",
    "                continue\n",
    "            \n",
    "            # Lấy tất cả các đuôi file ảnh (jpg, png...)\n",
    "            for ext in exts:\n",
    "                # Dùng glob để tìm đường dẫn file\n",
    "                for path in glob(os.path.join(label_dir, f\"*.{ext}\")):\n",
    "                    rows.append({\n",
    "                        \"image_path\": path, \n",
    "                        \"label\": label, \n",
    "                        \"subset\": subset if subset else None # Lưu thông tin train/test gốc nếu có\n",
    "                    })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4) GỘP DỮ LIỆU VÀ CÂN BẰNG (MERGE)\n",
    "# ============================================================\n",
    "\n",
    "def merge_datasets(dataset_cfgs, test_size=0.15, random_state=42):\n",
    "    \"\"\"\n",
    "    Load và gộp dữ liệu. Giữ nguyên tỉ lệ mất cân bằng (imbalanced) \n",
    "    để xử lý bằng Class Weight trong Loss Function.\n",
    "    \"\"\"\n",
    "    merged = []\n",
    "    print(\"--- Bắt đầu gộp dữ liệu ---\")\n",
    "\n",
    "    for cfg in dataset_cfgs:\n",
    "        # 1. Load thô\n",
    "        df = load_dataset(cfg[\"path\"])\n",
    "        if df.empty: continue\n",
    "\n",
    "        # 2. Chuẩn hóa nhãn (Map -> Lower -> Clean)\n",
    "        df['label'] = df['label'].str.lower().str.strip()\n",
    "        if \"label_map\" in cfg:\n",
    "            df['label'] = df['label'].map(cfg[\"label_map\"]).fillna(df['label'])\n",
    "        df = clean_labels(df)\n",
    "\n",
    "        # 3. Lọc subset (nếu chỉ lấy tập train của dataset nguồn)\n",
    "        if cfg.get(\"has_subset\", False) and \"subset\" in df.columns:\n",
    "            df = df[df[\"subset\"] == \"train\"]\n",
    "\n",
    "        merged.append(df)\n",
    "        print(f\" -> Đã thêm {len(df)} ảnh từ {cfg['path']}\")\n",
    "\n",
    "    if not merged:\n",
    "        raise ValueError(\"Không tìm thấy dữ liệu hợp lệ nào!\")\n",
    "\n",
    "    # 4. Gộp tất cả và Xáo trộn\n",
    "    df_all = pd.concat(merged, ignore_index=True)\n",
    "    \n",
    "    # 5. Chia Train/Val (Stratify để tập Val có tỉ lệ giống tập Train)\n",
    "    train_df, val_df = train_test_split(\n",
    "        df_all,\n",
    "        test_size=test_size,\n",
    "        stratify=df_all['label'],\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    print(f\"\\nTổng ảnh: {len(df_all)} (Train: {len(train_df)}, Val: {len(val_df)})\")\n",
    "    print(\"Phân bố Train (Chưa cân bằng):\", train_df['label'].value_counts().to_dict())\n",
    "\n",
    "    return train_df.reset_index(drop=True), val_df.reset_index(drop=True)\n",
    "\n",
    "# ============================================================\n",
    "# 5) DATA AUGMENTATION (TRANSFORMS)\n",
    "# ============================================================\n",
    "\n",
    "def get_transforms(img_size=112):\n",
    "    \"\"\"\n",
    "    Định nghĩa các phép biến đổi ảnh để làm phong phú dữ liệu (Augmentation).\n",
    "    \"\"\"\n",
    "    train_t = transforms.Compose([\n",
    "        transforms.Grayscale(1),                    # Chuyển về ảnh xám (1 kênh màu)\n",
    "        transforms.Resize(img_size + 16),           # Resize lớn hơn một chút\n",
    "        transforms.RandomResizedCrop(img_size, scale=(0.80, 1.0)), # Crop ngẫu nhiên\n",
    "        transforms.RandomHorizontalFlip(p=0.5),     # Lật ngang ảnh (gương)\n",
    "        transforms.RandomRotation(15),              # Xoay nhẹ tối đa 15 độ\n",
    "        transforms.ColorJitter(brightness=0.3, contrast=0.3), # Thay đổi độ sáng/tương phản\n",
    "        transforms.GaussianBlur(3),                 # Làm mờ nhẹ (giảm nhiễu hạt)\n",
    "        transforms.ToTensor(),                      # Chuyển sang Tensor và đưa về [0, 1]\n",
    "        transforms.Normalize([0.5], [0.5]),         # Chuẩn hóa về [-1, 1]\n",
    "        transforms.RandomErasing(p=0.4, scale=(0.02, 0.2)), # Xóa ngẫu nhiên 1 vùng nhỏ (tránh overfitting)\n",
    "    ])\n",
    "\n",
    "    val_t = transforms.Compose([\n",
    "        transforms.Grayscale(1),\n",
    "        transforms.Resize(img_size),\n",
    "        transforms.CenterCrop(img_size),            # Chỉ lấy phần trung tâm\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5]),\n",
    "    ])\n",
    "\n",
    "    return train_t, val_t\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6) DATASET CLASS (PYTORCH)\n",
    "# ============================================================\n",
    "\n",
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, df, transform, preload=False):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Tạo từ điển map từ Label (str) -> Index (int)\n",
    "        self.label_to_idx = {l: i for i, l in enumerate(VALID_CLASSES)}\n",
    "        self.idx_to_label = {i: l for l, i in self.label_to_idx.items()}\n",
    "        self.num_classes = len(VALID_CLASSES)\n",
    "\n",
    "        # Preload: Load toàn bộ ảnh vào RAM\n",
    "        self.preload = preload\n",
    "        self.cache = None\n",
    "        if preload:\n",
    "            print(\"Đang load toàn bộ ảnh vào RAM...\")\n",
    "            self.cache = [Image.open(p).convert('RGB') for p in tqdm(df['image_path'])]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        # Lấy ảnh từ cache hoặc đọc từ đĩa\n",
    "        if self.cache is not None:\n",
    "            img = self.cache[idx]\n",
    "        else:\n",
    "            img = Image.open(row['image_path']).convert('RGB')\n",
    "\n",
    "        # Áp dụng transform (augmentation)\n",
    "        img = self.transform(img)\n",
    "\n",
    "        # Chuyển nhãn thành số\n",
    "        label = self.label_to_idx[row['label']]\n",
    "        \n",
    "        return img, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "    # Hàm tính trọng số cho Loss Function (dùng khi dữ liệu mất cân bằng)\n",
    "    def get_class_weights(self):\n",
    "        counts = Counter([self.label_to_idx[l] for l in self.df['label']])\n",
    "        total = len(self.df)\n",
    "        # Công thức: weight = tổng / số lượng của class đó\n",
    "        weights = [total / counts[i] for i in range(self.num_classes)]\n",
    "        return torch.tensor(weights, dtype=torch.float)\n",
    "\n",
    "    # Hàm tạo Sampler (để bốc mẫu theo trọng số khi train)\n",
    "    def get_sampler(self):\n",
    "        counts = Counter([self.label_to_idx[l] for l in self.df['label']])\n",
    "        # Trọng số cho từng mẫu = 1 / số lượng class của mẫu đó\n",
    "        weights = [1.0 / counts[self.label_to_idx[l]] for l in self.df['label']]\n",
    "        return WeightedRandomSampler(weights, len(weights), replacement=True)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 7) CHƯƠNG TRÌNH CHÍNH (MAIN)\n",
    "# ============================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Cấu hình các folder dữ liệu\n",
    "    configs = [\n",
    "        # Dataset FERPlus, có sẵn folder train/test\n",
    "        {\"path\": \"/kaggle/input/ferplus\", \"has_subset\": True}, \n",
    "        # Dataset AffectNet, cần map lại nhãn\n",
    "        {\"path\": \"/kaggle/input/young-affectnet-hq\", \"label_map\": EMOTION_MAP}, \n",
    "    ]\n",
    "\n",
    "    # 1. Gộp và xử lý dữ liệu\n",
    "    train_df, val_df = merge_datasets(configs, test_size=0.1)\n",
    "\n",
    "    # 2. Lấy các phép transform\n",
    "    train_t, val_t = get_transforms(img_size=112)\n",
    "\n",
    "    # 3. Tạo Dataset\n",
    "    train_ds = EmotionDataset(train_df, train_t, preload=False)\n",
    "    val_ds = EmotionDataset(val_df, val_t, preload=False)\n",
    "\n",
    "    # 4. Tạo DataLoader\n",
    "    train_loader = DataLoader(train_ds, batch_size=128, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=128, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    print(\"\\nDataset đã sẵn sàng!\")\n",
    "    print(f\"Train samples: {len(train_ds)}\")\n",
    "    print(f\"Val samples:   {len(val_ds)}\")\n",
    "\n",
    "    # Lấy danh sách tên class\n",
    "    class_names = list(train_ds.label_to_idx.keys()) \n",
    "    class_weights = train_ds.get_class_weights()\n",
    "    print(f\"Classes: {class_names}\")\n",
    "    \n",
    "    # In thử 1 batch để kiểm tra shape\n",
    "    imgs, labels = next(iter(train_loader))\n",
    "    print(f\"Image batch shape: {imgs.shape}\") # Kỳ vọng: [64, 1, 112, 112] (1 kênh màu do Grayscale)\n",
    "    print(f\"Label batch shape: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Kiểm tra mapping nhãn\n",
    "print(train_df['label'].value_counts())\n",
    "\n",
    "# Kiểm tra trùng ảnh giữa train/val\n",
    "print(len(set(train_df['image_path']) & set(val_df['image_path'])))\n",
    "\n",
    "# Kiểm tra mapping label->idx\n",
    "print(train_ds.label_to_idx)\n",
    "\n",
    "# Kiểm tra shape ảnh đầu vào\n",
    "imgs, _ = next(iter(train_loader))\n",
    "print(imgs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_distribution(df, title):\n",
    "    counts = df['label'].value_counts().sort_index()\n",
    "    plt.figure(figsize=(8,4))\n",
    "    counts.plot(kind='bar', color='skyblue', edgecolor='black')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Emotion label\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "    plt.show()\n",
    "\n",
    "plot_distribution(train_df, \"Train Set Class Distribution\")\n",
    "plot_distribution(val_df, \"Validation Set Class Distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1. SE BLOCK (Squeeze-and-Excitation)\n",
    "# ============================================================\n",
    "class SEBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    SE Block giúp mô hình tập trung vào các đặc trưng quan trọng.\n",
    "    Cơ chế: \"Nhìn\" toàn bộ thông tin (Global Pooling) -> Tính trọng số cho từng kênh (FC layers).\n",
    "    \"\"\"\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super().__init__()\n",
    "        # Squeeze: Nén không gian (H, W) thành 1 điểm (1x1) để lấy thông tin tổng quát\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        # Excitation: Mạng nơ-ron nhỏ để học trọng số của các kênh\n",
    "        self.fc = nn.Sequential(\n",
    "            # Giảm số kênh xuống để tiết kiệm tham số\n",
    "            nn.Linear(channels, channels // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # Khôi phục lại số kênh ban đầu\n",
    "            nn.Linear(channels // reduction, channels, bias=False),\n",
    "            # Sigmoid đưa giá trị về khoảng [0, 1] (tương ứng mức độ quan trọng)\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        # y shape: [Batch, Channel]\n",
    "        y = self.avg_pool(x).view(b, c) \n",
    "        # y shape: [Batch, Channel, 1, 1]\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        \n",
    "        # Nhân trọng số (y) vào input gốc (x).\n",
    "        # Kênh nào quan trọng sẽ được giữ lại/khuếch đại, kênh nhiễu bị giảm đi.\n",
    "        return x * y\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. BASIC BLOCK + SE (Residual Block)\n",
    "# ============================================================\n",
    "class BasicBlockSE(nn.Module):\n",
    "    \"\"\"\n",
    "    Khối ResNet cơ bản có tích hợp SE Block và Dropout.\n",
    "    Cấu trúc: Conv -> BN -> ReLU -> Conv -> BN -> Dropout -> SE -> Add Residual -> ReLU\n",
    "    \"\"\"\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1, reduction=16, drop_prob=0.0):\n",
    "        super().__init__()\n",
    "\n",
    "        # Conv 1: Có thể giảm kích thước ảnh nếu stride > 1\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # Conv 2: Giữ nguyên kích thước\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # Tích hợp SE Block\n",
    "        self.se = SEBlock(out_channels, reduction=reduction)\n",
    "        \n",
    "        # Dropout xác suất thấp để tránh overfitting trên tập dữ liệu nhỏ\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "        # Shortcut (đường tắt): Dùng để cộng input vào output\n",
    "        self.shortcut = nn.Sequential()\n",
    "        # Nếu kích thước input khác output (do stride hoặc số kênh thay đổi),\n",
    "        # cần dùng Conv 1x1 để biến đổi input cho khớp shape để cộng được.\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.shortcut(x) # Lưu lại input gốc\n",
    "\n",
    "        # Luồng chính\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out, inplace=True)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        # Dropout (Regularization): Ngẫu nhiên tắt một số feature map khi train\n",
    "        if self.training and self.drop_prob > 0:\n",
    "            out = F.dropout2d(out, p=self.drop_prob, training=True)\n",
    "\n",
    "        # Áp dụng SE Attention\n",
    "        out = self.se(out)\n",
    "\n",
    "        # Cộng đường tắt (Residual Connection)\n",
    "        out += identity\n",
    "        out = F.relu(out, inplace=True)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. MAIN MODEL (EmotionResNet)\n",
    "# ============================================================\n",
    "class EmotionResNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Mạng ResNet tùy chỉnh:\n",
    "    - Input: 1 kênh (ảnh xám)\n",
    "    - Số kênh bắt đầu: 32 (nhỏ hơn ResNet gốc là 64)\n",
    "    - Số lớp: Tùy chỉnh (Stem + 4 Layer blocks + Classifier)\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=6, reduction=8, dropout=0.3, drop_prob=0.05):\n",
    "        super().__init__()\n",
    "\n",
    "        # Stem: Lớp xử lý đầu vào (Input 1 channel -> 32 channels)\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        # Các khối Residual (Layer 1 -> 4)\n",
    "        # layer1: 32 -> 32 channels (giữ nguyên size)\n",
    "        self.layer1 = self._make_layer(32, 32, blocks=2, stride=1, reduction=reduction, drop_prob=drop_prob)\n",
    "        # layer2: 32 -> 64 channels (giảm size /2)\n",
    "        self.layer2 = self._make_layer(32, 64, blocks=2, stride=2, reduction=reduction, drop_prob=drop_prob)\n",
    "        # layer3: 64 -> 128 channels (giảm size /2)\n",
    "        self.layer3 = self._make_layer(64, 128, blocks=1, stride=2, reduction=reduction, drop_prob=drop_prob) \n",
    "        # layer4: 128 -> 256 channels (giảm size /2)\n",
    "        self.layer4 = self._make_layer(128, 256, blocks=2, stride=2, reduction=reduction, drop_prob=drop_prob)\n",
    "\n",
    "        # Classifier\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout),          # Dropout ở lớp cuối cực quan trọng\n",
    "            nn.Linear(256, num_classes)   # Output ra số lớp cảm xúc\n",
    "        )\n",
    "\n",
    "    def _make_layer(self, in_c, out_c, blocks, stride, reduction, drop_prob):\n",
    "        layers = []\n",
    "        # Block đầu tiên của layer chịu trách nhiệm thay đổi stride/channel\n",
    "        layers.append(BasicBlockSE(in_c, out_c, stride, reduction, drop_prob))\n",
    "        \n",
    "        # Các block tiếp theo giữ nguyên stride=1 và channel\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(BasicBlockSE(out_c, out_c, 1, reduction, drop_prob))\n",
    "            \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Trích xuất đặc trưng (Feature Extraction)\n",
    "        x = self.stem(x)      # [B, 32, H, W]\n",
    "        x = self.layer1(x)    # [B, 32, H, W]\n",
    "        x = self.layer2(x)    # [B, 64, H/2, W/2]\n",
    "        x = self.layer3(x)    # [B, 128, H/4, W/4]\n",
    "        x = self.layer4(x)    # [B, 256, H/8, W/8]\n",
    "\n",
    "        # Phân loại (Classification)\n",
    "        x = self.avgpool(x)   # [B, 256, 1, 1]\n",
    "        x = x.view(x.size(0), -1) # Flatten -> [B, 256]\n",
    "        x = self.classifier(x)    # [B, num_classes]\n",
    "        return x\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# TEST\n",
    "# ============================================================\n",
    "if __name__ == \"__main__\":\n",
    "    # Giả lập input: Batch=1, Channel=1 (Gray), Size=112x112\n",
    "    dummy_input = torch.randn(1, 1, 112, 112)\n",
    "    \n",
    "    model = EmotionResNet(num_classes=7)\n",
    "    \n",
    "    # Tính tổng số tham số (Parameters)\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    # Chạy thử forward pass\n",
    "    output = model(dummy_input)\n",
    "    \n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Model: EmotionResNet\")\n",
    "    print(f\"Total Params: {total_params / 1e6:.2f}M (Triệu tham số)\")\n",
    "    print(f\"Output Shape: {output.shape}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainning - Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1. CÁC HÀM TÍNH TOÁN CHỈ SỐ (METRICS)\n",
    "# ============================================================\n",
    "\n",
    "def compute_metrics(y_true, y_pred, labels=None):\n",
    "    \"\"\"\n",
    "    Tính độ chính xác (Accuracy) và ma trận nhầm lẫn (Confusion Matrix).\n",
    "    \"\"\"\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    return acc, cm\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. HÀM HUẤN LUYỆN VÀ ĐÁNH GIÁ (MAIN LOOP)\n",
    "# ============================================================\n",
    "\n",
    "def train_and_evaluate(\n",
    "    in_dir=\"input\",\n",
    "    out_dir=\"checkpoints\",\n",
    "    history_dir=\"history\",\n",
    "    img_size=48,\n",
    "    epochs=30,\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-4,\n",
    "    device=None,\n",
    "    label_smoothing=0.05,\n",
    "    early_stop_patience=20\n",
    "):\n",
    "    \n",
    "    # --- 1. Thiết lập thư mục và đường dẫn lưu model ---\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    ckpt_path = os.path.join(out_dir, \"best_emotion.pth\")\n",
    "    final_ckpt_path = os.path.join(out_dir, \"final_emotion.pth\")\n",
    "    history_path = os.path.join(out_dir, \"history.json\")\n",
    "\n",
    "    # --- 2. Cấu hình thiết bị (Device) ---\n",
    "    # Ưu tiên GPU nếu có, fallback về CPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") if device is None else device\n",
    "    device_type = \"cuda\" if device.type == \"cuda\" else \"cpu\"\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    print(f\"Using device: {device}\")\n",
    "    if device.type == \"cuda\":\n",
    "        print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "    # --- 3. Chuẩn bị Data Transforms ---\n",
    "    train_t, val_t = get_transforms(img_size)\n",
    "\n",
    "    # --- 4. Khởi tạo Model ---\n",
    "    model = EmotionResNet(num_classes=len(train_ds.label_to_idx))\n",
    "    \n",
    "    # Hỗ trợ chạy trên nhiều GPU (Multi-GPU)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(f\"Using {torch.cuda.device_count()} GPUs via DataParallel\")\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # --- 5. Cấu hình Loss, Optimizer, Scheduler ---\n",
    "    # Lấy class weights để xử lý mất cân bằng dữ liệu\n",
    "    class_weights = train_ds.get_class_weights().to(device)\n",
    "    \n",
    "    # Hàm loss có label smoothing và trọng số lớp\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing, weight=class_weights)\n",
    "    \n",
    "    # Optimizer AdamW\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    # Scheduler: Kết hợp Warmup (tăng dần LR) và Cosine Annealing (giảm dần LR)\n",
    "    warmup_epochs = max(1, int(epochs * 0.05))\n",
    "    warmup = LinearLR(optimizer, start_factor=0.2, total_iters=warmup_epochs)\n",
    "    cosine = CosineAnnealingLR(optimizer, T_max=max(1, epochs - warmup_epochs))\n",
    "    scheduler = SequentialLR(optimizer, schedulers=[warmup, cosine], milestones=[warmup_epochs])\n",
    "    \n",
    "    # Scaler cho Mixed Precision Training (FP16)\n",
    "    scaler = amp.GradScaler(enabled=(device.type == \"cuda\"))\n",
    "\n",
    "    # --- 6. Logic Resume (Khôi phục training từ checkpoint) ---\n",
    "    best_val, start_epoch, best_epoch, no_improve = 0.0, 0, 0, 0\n",
    "    history = {\"train_loss\": [], \"val_loss\": [], \"train_acc\": [], \"val_acc\": []}\n",
    "\n",
    "    # Kiểm tra xem file checkpoint có tồn tại không\n",
    "    if os.path.exists(in_dir):\n",
    "        ckpt = torch.load(in_dir, map_location=device)\n",
    "        \n",
    "        # Load trạng thái model, optimizer, scheduler\n",
    "        model.load_state_dict(ckpt[\"model_state\"])\n",
    "        if \"optimizer_state\" in ckpt:\n",
    "            optimizer.load_state_dict(ckpt[\"optimizer_state\"])\n",
    "        if \"scheduler_state\" in ckpt:\n",
    "            scheduler.load_state_dict(ckpt[\"scheduler_state\"])\n",
    "        print(f\"[INFO] Loaded existing model from {ckpt_path}\")\n",
    "\n",
    "        # Load lịch sử training cũ\n",
    "        if os.path.exists(history_dir):\n",
    "            with open(history_dir, \"r\") as f:\n",
    "                history = json.load(f)\n",
    "            best_val = max(history[\"val_acc\"]) / 100\n",
    "            start_epoch = len(history[\"val_acc\"])\n",
    "            best_epoch = start_epoch - 1\n",
    "            print(f\"[INFO] Resuming training from epoch {start_epoch}, best val acc = {best_val*100:.2f}%\")\n",
    "\n",
    "    # Tạo danh sách tên các nhãn để in báo cáo\n",
    "    label_list = [train_ds.idx_to_label[i] for i in range(len(train_ds.idx_to_label))]\n",
    "\n",
    "    # ============================================================\n",
    "    # VÒNG LẶP TRAINING (TRAINING LOOP)\n",
    "    # ============================================================\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "\n",
    "        # --- A. Quá trình Train ---\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        y_true_train, y_pred_train = [], []\n",
    "        \n",
    "        # Thanh tiến trình cho tập train\n",
    "        pbar = tqdm(train_loader, desc=f\"Train Epoch {epoch+1}/{epochs}\", leave=False)\n",
    "\n",
    "        for imgs, labels in pbar:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            \n",
    "            # Xóa gradient cũ\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            \n",
    "            # Huấn luyện với Mixed Precision (AMP)\n",
    "            with amp.autocast(device_type=\"cuda\", enabled=(device.type==\"cuda\")):\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward và cập nhật trọng số với Scaler\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0) # Gradient Clipping\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            # Tính toán loss và lưu kết quả dự đoán\n",
    "            running_loss += loss.item() * imgs.size(0)\n",
    "            preds = outputs.argmax(dim=1).detach().cpu().numpy()\n",
    "            y_pred_train.extend(preds.tolist())\n",
    "            y_true_train.extend(labels.detach().cpu().numpy().tolist())\n",
    "\n",
    "        # Tính metrics cho tập train\n",
    "        train_loss = running_loss / len(train_ds)\n",
    "        train_acc, _ = compute_metrics(y_true_train, y_pred_train)\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_acc\"].append(train_acc * 100)\n",
    "\n",
    "        # --- B. Quá trình Validation ---\n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        y_true, y_pred = [], []\n",
    "        \n",
    "        # Không tính gradient khi validation\n",
    "        with torch.no_grad(), amp.autocast(device_type=\"cuda\", enabled=(device.type==\"cuda\")):\n",
    "            for imgs, labels in tqdm(val_loader, desc=f\"Val Epoch {epoch+1}/{epochs}\", leave=False):\n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "                \n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                running_val_loss += loss.item() * imgs.size(0)\n",
    "                preds = outputs.argmax(dim=1).detach().cpu().numpy()\n",
    "                y_pred.extend(preds.tolist())\n",
    "                y_true.extend(labels.detach().cpu().numpy().tolist())\n",
    "\n",
    "        # Tính metrics cho tập val\n",
    "        val_loss = running_val_loss / len(val_ds)\n",
    "        val_acc, cm = compute_metrics(y_true, y_pred, labels=list(range(len(train_ds.idx_to_label))))\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_acc\"].append(val_acc * 100)\n",
    "\n",
    "        # --- C. Logging định kỳ (Mỗi 5 epoch) ---\n",
    "        if epoch % 5 == 0:\n",
    "            print(\"Class distribution check:\")\n",
    "            # Đếm số lượng dự đoán so với thực tế\n",
    "            pred_counts = {label_list[i]: (np.array(y_pred) == i).sum() for i in range(len(label_list))}\n",
    "            true_counts = {label_list[i]: (np.array(y_true) == i).sum() for i in range(len(label_list))}\n",
    "            \n",
    "            for lbl in label_list:\n",
    "                ratio = pred_counts[lbl] / max(1, true_counts[lbl])\n",
    "                print(f\"  {lbl:<15} pred={pred_counts[lbl]:<6} true={true_counts[lbl]:<6} ratio={ratio:.2f}x\")\n",
    "            \n",
    "            # In báo cáo chi tiết (Precision, Recall, F1)\n",
    "            report = classification_report(y_true, y_pred, target_names=label_list, digits=3)\n",
    "            print(\"\\nPer-class performance:\")\n",
    "            print(report)\n",
    "\n",
    "        # Cập nhật Learning Rate\n",
    "        scheduler.step()\n",
    "        current_lr = scheduler.get_last_lr()[0]\n",
    "\n",
    "        # In kết quả Epoch hiện tại\n",
    "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "        print(f\"LR: {current_lr:.2e}\")\n",
    "        print(\"=\" * 70)\n",
    "        print(\"Results:\")\n",
    "        print(f\"  Train: loss={train_loss:.4f}, acc={train_acc*100:.2f}%\")\n",
    "        print(f\"  Val:   loss={val_loss:.4f}, acc={val_acc*100:.2f}%\")\n",
    "        print()\n",
    "\n",
    "        # --- D. Checkpoint & Early Stopping ---\n",
    "        # Nếu kết quả tốt hơn tốt nhất trước đó -> Lưu model\n",
    "        if val_acc > best_val + 1e-6:\n",
    "            best_val = val_acc\n",
    "            best_epoch = epoch\n",
    "            ckpt = {\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state\": model.state_dict(),\n",
    "                \"optimizer_state\": optimizer.state_dict(),\n",
    "                \"scheduler_state\": scheduler.state_dict(),\n",
    "                \"label_to_idx\": train_ds.label_to_idx\n",
    "            }\n",
    "            torch.save(ckpt, ckpt_path)\n",
    "            print(f\"[INFO] Saved best model (val_acc={val_acc*100:.2f}%)\")\n",
    "            no_improve = 0\n",
    "        else:\n",
    "            # Nếu không cải thiện -> Tăng biến đếm\n",
    "            no_improve += 1\n",
    "            if no_improve >= early_stop_patience:\n",
    "                print(f\"[INFO] Early stopping at epoch {epoch+1}, best epoch {best_epoch+1}\")\n",
    "                # Lưu trạng thái cuối cùng trước khi dừng\n",
    "                torch.save({\n",
    "                    \"epoch\": epoch,\n",
    "                    \"model_state\": model.state_dict(),\n",
    "                    \"optimizer_state\": optimizer.state_dict(),\n",
    "                    \"scheduler_state\": scheduler.state_dict(),\n",
    "                    \"label_to_idx\": train_ds.label_to_idx\n",
    "                }, final_ckpt_path)\n",
    "                break\n",
    "\n",
    "        # Lưu history vào file JSON\n",
    "        with open(history_path, \"w\") as f:\n",
    "            json.dump(history, f, indent=2)\n",
    "\n",
    "        # Nếu là epoch cuối cùng -> Lưu model\n",
    "        if epoch == epochs:\n",
    "            torch.save({\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state\": model.state_dict(),\n",
    "                \"optimizer_state\": optimizer.state_dict(),\n",
    "                \"scheduler_state\": scheduler.state_dict(),\n",
    "                \"label_to_idx\": train_ds.label_to_idx\n",
    "            }, final_ckpt_path)\n",
    "\n",
    "    # --- 7. Vẽ biểu đồ (Plotting) ---\n",
    "    plt.figure(figsize=(10,4))\n",
    "    \n",
    "    # Biểu đồ Loss\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(history[\"train_loss\"], label=\"train_loss\")\n",
    "    plt.plot(history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.legend(); plt.title(\"Loss\")\n",
    "    \n",
    "    # Biểu đồ Accuracy\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(history[\"train_acc\"], label=\"train_acc\")\n",
    "    plt.plot(history[\"val_acc\"], label=\"val_acc\")\n",
    "    plt.legend(); plt.title(\"Accuracy\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Best val acc: {best_val*100:.2f}% at epoch {best_epoch+1}\")\n",
    "    \n",
    "    # Trả về model, history và danh sách nhãn\n",
    "    return model, history, train_ds.idx_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "        \n",
    "    model, history, idx2label = train_and_evaluate(in_dir=\"/kaggle/input/emotion-model/pytorch/default/1/best_emotion.pth\",\n",
    "                                                   out_dir=\"checkpoints\",\n",
    "                                                   history_dir=\"/kaggle/input/emotion-model/pytorch/default/1/history.json\",\n",
    "                                                   img_size=112,\n",
    "                                                   epochs=300,\n",
    "                                                   lr=3e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "history_dir=\"/kaggle/input/emotion-model/pytorch/default/1/history.json\"\n",
    "if os.path.exists(history_dir):\n",
    "    with open(history_dir, \"r\") as f:\n",
    "        history = json.load(f)\n",
    "    best_val = max(history[\"val_acc\"]) / 100\n",
    "    start_epoch = len(history[\"val_acc\"])\n",
    "    best_epoch = start_epoch - 1\n",
    "\n",
    "# --- Plot ---\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history[\"train_loss\"], label=\"train_loss\")\n",
    "plt.plot(history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.legend(); plt.title(\"Loss\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history[\"train_acc\"], label=\"train_acc\")\n",
    "plt.plot(history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.legend(); plt.title(\"Accuracy\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def predict_from_url(model, url, transform, idx_to_label, device=None, show_image=True, top_k=None):\n",
    "    \"\"\"\n",
    "    Dự đoán cảm xúc từ URL ảnh.\n",
    "    Hiển thị top xác suất và biểu đồ cho toàn bộ lớp.\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") if device is None else device\n",
    "\n",
    "    try:\n",
    "        # --- Gửi request ---\n",
    "        headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # --- Kiểm tra xem có phải là ảnh không ---\n",
    "        content_type = response.headers.get(\"Content-Type\", \"\")\n",
    "        if \"image\" not in content_type:\n",
    "            raise ValueError(f\"URL không trả về ảnh. Content-Type: {content_type}\")\n",
    "\n",
    "        # --- Mở ảnh ---\n",
    "        # BytesIO giúp đọc dữ liệu binary từ RAM như một file\n",
    "        image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "\n",
    "    except (UnidentifiedImageError, ValueError) as e:\n",
    "        print(f\"[ERROR] Không thể mở ảnh từ URL: {url}\\nLý do: {e}\")\n",
    "        return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Lỗi khi tải ảnh: {e}\")\n",
    "        return None, None\n",
    "\n",
    "    # --- Hiển thị ảnh ---\n",
    "    if show_image:\n",
    "        plt.imshow(image)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(\"Input Image\")\n",
    "        plt.show()\n",
    "\n",
    "    # --- Tiền xử lý (Transform) ---\n",
    "    # unsqueeze(0) để tạo batch size = 1: [C, H, W] -> [1, C, H, W]\n",
    "    img_tensor = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    # --- Dự đoán ---\n",
    "    with torch.no_grad(): # Không tính gradient\n",
    "        outputs = model(img_tensor)\n",
    "        # Softmax để chuyển output thành xác suất (0-1)\n",
    "        probs = F.softmax(outputs, dim=1).cpu().numpy()[0]\n",
    "\n",
    "    # --- Xử lý kết quả ---\n",
    "    emotions = [idx_to_label[i] for i in range(len(probs))]\n",
    "    sorted_idx = probs.argsort()[::-1]  # Sắp xếp index theo xác suất giảm dần\n",
    "    top_k = top_k or len(emotions) # Nếu không chỉ định top_k thì lấy hết\n",
    "\n",
    "    print(\"Top dự đoán:\")\n",
    "    for i in range(top_k):\n",
    "        lbl = emotions[sorted_idx[i]]\n",
    "        conf = probs[sorted_idx[i]] * 100\n",
    "        print(f\"  {i+1}. {lbl:10s} : {conf:.2f}%\")\n",
    "\n",
    "    # --- Biểu đồ xác suất ---\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    # Đảo ngược list để class có xác suất cao nhất nằm trên cùng biểu đồ ngang\n",
    "    plt.barh([emotions[i] for i in sorted_idx[::-1]],\n",
    "             [probs[i]*100 for i in sorted_idx[::-1]],\n",
    "             color=\"skyblue\")\n",
    "    plt.xlabel(\"Probability (%)\")\n",
    "    plt.title(\"Emotion Probabilities\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # --- Trả về nhãn cao nhất ---\n",
    "    pred_label = emotions[sorted_idx[0]]\n",
    "    pred_conf = probs[sorted_idx[0]]\n",
    "    return pred_label, pred_conf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_model_for_inference(ckpt_path, device=None):\n",
    "    \"\"\"\n",
    "    Load trọng số model từ file checkpoint   \n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") if device is None else device\n",
    "    \n",
    "    # Load file checkpoint\n",
    "    print(f\"[INFO] Loading checkpoint from: {ckpt_path}\")\n",
    "    ckpt = torch.load(ckpt_path, map_location=device)\n",
    "    \n",
    "    # Khôi phục dictionary nhãn\n",
    "    label_to_idx = ckpt[\"label_to_idx\"]\n",
    "    idx_to_label = {v: k for k, v in label_to_idx.items()}\n",
    "\n",
    "    # Khởi tạo kiến trúc model\n",
    "    model = EmotionResNet(num_classes=len(label_to_idx))\n",
    "    \n",
    "    state_dict = ckpt[\"model_state\"]\n",
    "    \n",
    "    # Kiểm tra xem key đầu tiên có chứa 'module.'(DataParallel)\n",
    "    if list(state_dict.keys())[0].startswith('module.'):\n",
    "        print(\"[INFO] Detected DataParallel checkpoint. Removing 'module.' prefix...\")\n",
    "        # Tạo state_dict mới bằng cách bỏ chữ 'module.' ở đầu mỗi key\n",
    "        new_state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}\n",
    "        model.load_state_dict(new_state_dict)\n",
    "    else:\n",
    "        # Nếu không có 'module.', load bình thường\n",
    "        model.load_state_dict(state_dict)\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    print(f\"[INFO] Model loaded successfully!\")\n",
    "    return model, idx_to_label\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Cấu hình thiết bị\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Đường dẫn checkpoint\n",
    "    ckpt_path = \"/kaggle/input/emotion-model/pytorch/default/1/best_emotion.pth\"\n",
    "\n",
    "    # 1. Load model\n",
    "    if os.path.exists(ckpt_path):\n",
    "        model, idx_to_label = load_model_for_inference(ckpt_path, device)\n",
    "\n",
    "        # 2. Lấy transform\n",
    "        _, val_t = get_transforms(img_size=112)\n",
    "\n",
    "        # 3. Link ảnh test\n",
    "        url = \"https://t4.ftcdn.net/jpg/00/68/69/59/360_F_68695981_GuWIHWfB0l5wJ2al8rv4xZRUqUtwIo2P.jpg\"\n",
    "\n",
    "        # 4. Thực hiện dự đoán\n",
    "        predict_from_url(model, url, val_t, idx_to_label, device)\n",
    "    else:\n",
    "        print(f\"[ERROR] Checkpoint not found at: {ckpt_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dowload checkpoints.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from IPython.display import FileLink, display\n",
    "\n",
    "def download_file(path, download_file_name):\n",
    "    os.chdir('/kaggle/working/')\n",
    "    zip_name = f\"/kaggle/working/{download_file_name}.zip\"\n",
    "    command = f\"zip {zip_name} {path} -r\"\n",
    "    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "    if result.returncode != 0:\n",
    "        print(\"Unable to run zip command!\")\n",
    "        print(result.stderr)\n",
    "        return\n",
    "    display(FileLink(f'{download_file_name}.zip'))\n",
    "    \n",
    "download_file('/kaggle/working/checkpoints', 'checkpoints') "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 2552913,
     "sourceId": 4335759,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4401497,
     "sourceId": 8110231,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 511046,
     "modelInstanceId": 495648,
     "sourceId": 655787,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
