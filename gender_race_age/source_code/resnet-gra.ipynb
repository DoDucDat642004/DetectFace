{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":78156,"sourceType":"datasetVersion","datasetId":44109},{"sourceId":1547126,"sourceType":"datasetVersion","datasetId":912830},{"sourceId":656249,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":495996,"modelId":511404}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Data : \n#     +) https://www.kaggle.com/datasets/aibloy/fairface\n#     +) https://www.kaggle.com/datasets/jangedoo/utkface-new","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# 1. STANDARD LIBRARIES (Thư viện chuẩn Python)\n# ============================================================\nimport os\nimport math\nimport random\nfrom glob import glob\nfrom typing import Dict\nfrom collections import Counter\n\n# ============================================================\n# 2. DATA SCIENCE & UTILITIES (Xử lý dữ liệu & Ảnh)\n# ============================================================\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom tqdm.notebook import tqdm\n\n# Scikit-learn\nfrom sklearn.model_selection import train_test_split\n\n# ============================================================\n# 3. PYTORCH FRAMEWORK\n# ============================================================\nimport torch\nimport torch.nn as nn\nimport torch.serialization\n\n# Data Handling\nfrom torch.utils.data import Dataset, DataLoader\n\n# Mixed Precision Training (Tăng tốc & giảm VRAM)\nfrom torch.cuda.amp import autocast, GradScaler\n\n# Computer Vision\nimport torchvision.transforms as T\nfrom torchvision import datasets  ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data processing","metadata":{}},{"cell_type":"code","source":"# # --- Load dữ liệu gốc ---\n# train_df = pd.read_csv(\"/kaggle/input/fairface/FairFace/train_labels.csv\")\n# val_df   = pd.read_csv(\"/kaggle/input/fairface/FairFace/val_labels.csv\")\n\n# # --- Làm sạch & thêm đường dẫn ---\n# for df, subset in [(train_df, \"train\"), (val_df, \"val\")]:\n#     df.drop(columns=['service_test'], errors='ignore', inplace=True)\n#     df['file'] = df['file'].apply(lambda f: os.path.join(\"/kaggle/input/fairface/FairFace\", f))\n#     df['file'] = df['file'].str.replace(f\"{subset}/{subset}\", subset)\n\n# # --- Mapping nhãn ---\n# gender_map = {'Male': 0, 'Female': 1}\n# race_map = {\n#     'White': 0, 'Black': 1, 'Latino_Hispanic': 2,\n#     'East Asian': 3, 'Southeast Asian': 4, 'Indian': 5, 'Middle Eastern': 6\n# }\n# age_map = {\n#     '0-2': 0, '3-9': 1, '10-19': 2, '20-29': 3,\n#     '30-39': 4, '40-49': 5, '50-59': 6, '60-69': 7, 'more than 70': 8\n# }\n\n# train_df['gender'] = train_df['gender'].map(gender_map)\n# val_df['gender']   = val_df['gender'].map(gender_map)\n# train_df['race']   = train_df['race'].map(race_map)\n# val_df['race']     = val_df['race'].map(race_map)\n# train_df['age']    = train_df['age'].map(age_map)\n# val_df['age']      = val_df['age'].map(age_map)\n\n# # --- Chia riêng theo task ---\n# train_gender_df = train_df[['file', 'gender']].copy()\n# val_gender_df   = val_df[['file', 'gender']].copy()\n\n# train_race_df = train_df[['file', 'race']].copy()\n# val_race_df   = val_df[['file', 'race']].copy()\n\n# train_age_df = train_df[['file', 'age']].copy()\n# val_age_df   = val_df[['file', 'age']].copy()\n","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# 1. UTILS (CÔNG CỤ HỖ TRỢ)\n# ============================================================\ndef set_seed(seed=42):\n    \"\"\"\n    Thiết lập hạt giống ngẫu nhiên (seed) cố định để đảm bảo kết quả \n    có thể tái lập (reproducible) mỗi lần chạy.\n    \"\"\"\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\n\n# ============================================================\n# 2. LOAD DATASET: FAIRFACE\n# ============================================================\ndef load_fairface(base_dir: str):\n    \"\"\"\n    Đọc dữ liệu từ bộ FairFace.\n    - Input: Đường dẫn thư mục gốc.\n    - Output: DataFrame train và validation đã được chuẩn hóa nhãn.\n    \"\"\"\n    # Đọc file CSV nhãn\n    train_df = pd.read_csv(os.path.join(base_dir, \"train_labels.csv\"))\n    val_df = pd.read_csv(os.path.join(base_dir, \"val_labels.csv\"))\n\n    # Bản đồ ánh xạ nhãn từ chuỗi sang số nguyên (Integer Mapping)\n    gender_map = {'Male': 0, 'Female': 1}\n    race_map = {\n        'White': 0, 'Black': 1, 'Latino_Hispanic': 2,\n        'East Asian': 3, 'Southeast Asian': 4,\n        'Indian': 5, 'Middle Eastern': 6\n    }\n    # Chia độ tuổi thành 9 nhóm\n    age_map = {\n        '0-2': 0, '3-9': 1, '10-19': 2, '20-29': 3,\n        '30-39': 4, '40-49': 5, '50-59': 6,\n        '60-69': 7, 'more than 70': 8\n    }\n\n    # Xử lý từng tập dữ liệu (train/val)\n    for df, subset in [(train_df, \"train\"), (val_df, \"val\")]:\n        # Sửa lại đường dẫn file ảnh cho đúng cấu trúc thư mục\n        df[\"file\"] = df[\"file\"].apply(\n            lambda f: os.path.join(base_dir, f.replace(f\"{subset}/{subset}\", subset))\n        )\n        # Áp dụng mapping\n        df[\"gender\"] = df[\"gender\"].map(gender_map)\n        df[\"race\"] = df[\"race\"].map(race_map)\n        df[\"age\"] = df[\"age\"].map(age_map)\n        \n        # Bỏ các dòng thiếu dữ liệu\n        df.dropna(subset=[\"gender\", \"race\", \"age\"], inplace=True)\n\n    return train_df[[\"file\",\"age\",\"race\",\"gender\"]], \\\n           val_df[[\"file\",\"age\",\"race\",\"gender\"]]\n\n\n# ============================================================\n# 3. LOAD DATASET: UTKFACE\n# ============================================================\ndef load_utkface(utk_dir: str):\n    \"\"\"\n    Đọc dữ liệu từ bộ UTKFace.\n    - Đặc điểm: Tên file chứa thông tin nhãn (VD: 20_1_0_timestamp.jpg -> Tuổi 20, Nam, White).\n    - Cần map lại chủng tộc và nhóm tuổi để khớp với chuẩn của FairFace.\n    \"\"\"\n    recs = []\n    for f in os.listdir(utk_dir):\n        if not f.lower().endswith((\".jpg\",\".png\",\".jpeg\")):\n            continue\n        \n        # Phân tích tên file: Age_Gender_Race_Date\n        parts = f.split(\"_\")\n        if len(parts) < 4:\n            continue\n        try:\n            age, gender, race = int(parts[0]), int(parts[1]), int(parts[2])\n        except:\n            continue\n            \n        # Lọc nhiễu: Bỏ các tuổi quá lớn\n        if age > 120:\n            continue\n\n        recs.append([os.path.join(utk_dir, f), age, gender, race])\n\n    df = pd.DataFrame(recs, columns=[\"file\",\"age_raw\",\"gender\",\"race\"])\n\n    # 1. Xử lý Tuổi: Chuyển tuổi cụ thể (continuous) sang 9 nhóm (bins) giống FairFace\n    # Bins: 0-2, 3-9, 10-19, 20-29, ...\n    bins = [2, 9, 19, 29, 39, 49, 59, 69, 200]\n    df[\"age\"] = df[\"age_raw\"].apply(lambda a: next(i for i, b in enumerate(bins) if a <= b))\n\n    # 2. Xử lý Race: Map từ UTK sang FairFace\n    # UTK: 0:White, 1:Black, 2:Asian, 3:Indian, 4:Others\n    # FairFace: 0:White, 1:Black, 3:East Asian, 5:Indian, 6:Middle Eastern\n    df[\"race\"] = (\n        df[\"race\"]\n        .map({0:0, 1:1, 2:3, 3:5, 4:6}) \n        .dropna()\n        .astype(int)\n    )\n\n    df = df[[\"file\",\"age\",\"race\",\"gender\"]]\n    \n    # Chia train/val tỉ lệ 80/20, phân tầng (stratify) theo Race để đảm bảo cân bằng\n    train_df, val_df = train_test_split(\n        df, test_size=0.2, random_state=42, stratify=df[\"race\"]\n    )\n    return train_df.reset_index(drop=True), val_df.reset_index(drop=True)\n\n\n# ============================================================\n# 4. PYTORCH DATASET CLASS\n# ============================================================\nclass MultiTaskFaceDataset(Dataset):\n    \"\"\"\n    Dataset tùy chỉnh để load ảnh và trả về 3 nhãn cùng lúc (Tuổi, Race, Giới tính).\n    \"\"\"\n    def __init__(self, df, transform=None):\n        # Kiểm tra sự tồn tại của file ảnh, bỏ qua nếu file lỗi/không có\n        exists_mask = df[\"file\"].map(os.path.exists)\n        if not exists_mask.all():\n            print(f\"Cảnh báo: Bỏ qua {(~exists_mask).sum()} file không tồn tại.\")\n            df = df[exists_mask]\n\n        self.df = df.reset_index(drop=True)\n        self.transform = transform\n\n    def __len__(self): \n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        \n        # Load ảnh và xử lý lỗi (nếu ảnh hỏng thì tạo ảnh đen để code không crash)\n        try:\n            img = Image.open(row[\"file\"]).convert(\"RGB\")\n        except:\n            img = Image.new(\"RGB\", (112,112), (0,0,0))\n\n        # Áp dụng Augmentation (nếu có)\n        if self.transform:\n            img = self.transform(img)\n\n        # Trả về dictionary các nhãn\n        labels = {\n            \"age\":    torch.tensor(int(row[\"age\"]), dtype=torch.long),\n            \"race\":   torch.tensor(int(row[\"race\"]), dtype=torch.long),\n            \"gender\": torch.tensor(int(row[\"gender\"]), dtype=torch.long),\n        }\n        return img, labels\n\n\n# ============================================================\n# 5. DATA BALANCING (CÂN BẰNG DỮ LIỆU)\n# ============================================================\ndef balance_train_data(train_df, val_df):\n    \"\"\"\n    Kỹ thuật cân bằng lại dữ liệu huấn luyện.\n    Do dữ liệu khuôn mặt thường bị lệch (ví dụ: quá nhiều người Da trắng, tuổi 20-30),\n    hàm này giúp lấy mẫu lại (Resampling) để các nhóm (Tuổi + Race + Gender) đồng đều hơn.\n    \"\"\"\n    print(\"Đang gộp train + val để tính toán lại phân phối...\")\n    combined = pd.concat([train_df, val_df], ignore_index=True)\n\n    # Tạo tổ hợp key duy nhất: (Tuổi, Race, Gender)\n    combined[\"combo\"] = list(zip(combined[\"age\"], combined[\"race\"], combined[\"gender\"]))\n    group_counts = combined[\"combo\"].value_counts()\n\n    # Tính số lượng mẫu mục tiêu (trung bình giữa nhóm ít nhất và nhiều nhất)\n    min_c, max_c = group_counts.min(), group_counts.max()\n    target = int((min_c + max_c) / 2)\n\n    print(f\"⚖️ Mục tiêu mỗi nhóm (Target per combo): {target}\")\n    balanced_parts = []\n\n    for combo, count in group_counts.items():\n        subset = combined[combined[\"combo\"]==combo]\n        if count > target:\n            # Downsampling: Nếu nhiều hơn target -> Lấy ngẫu nhiên đúng bằng target\n            subset = subset.sample(target, random_state=42)\n        else:\n            # Upsampling: Nếu ít hơn target -> Nhân bản (replace=True) lên cho đủ target\n            subset = subset.sample(target, replace=True, random_state=42)\n        balanced_parts.append(subset)\n\n    balanced = pd.concat(balanced_parts).reset_index(drop=True)\n    print(f\"Tổng số mẫu sau khi cân bằng: {len(balanced):,}\")\n\n    # Chia lại train/val sau khi đã cân bằng (Stratify theo Race)\n    train_df, val_df = train_test_split(\n        balanced,\n        test_size=0.1,\n        random_state=42,\n        stratify=balanced[\"race\"]\n    )\n\n    return train_df.drop(columns=[\"combo\"]), val_df.drop(columns=[\"combo\"])\n\n# ============================================================\n# 6. MAIN EXECUTION\n# ============================================================\nif __name__ == \"__main__\":\n    set_seed(42)\n\n    # Cấu hình đường dẫn\n    FAIRFACE_DIR = \"/kaggle/input/fairface/FairFace\"\n    UTK_DIR = \"/kaggle/input/utkface-new/UTKFace\"\n\n    # 1. Load dữ liệu thô\n    print(\"--> Đang load FairFace...\")\n    ff_train, ff_val = load_fairface(FAIRFACE_DIR)\n    print(\"--> Đang load UTKFace...\")\n    utk_train, utk_val = load_utkface(UTK_DIR)\n\n    # 2. Gộp dữ liệu từ 2 nguồn\n    train_df = pd.concat([ff_train, utk_train], ignore_index=True)\n    val_df = pd.concat([ff_val, utk_val], ignore_index=True)\n\n    # 3. Cân bằng dữ liệu (Quan trọng để tránh bias)\n    train_df, val_df = balance_train_data(train_df, val_df)\n\n    print(\"\\nPhân bố dữ liệu sau khi xử lý (Train):\")\n    for col in [\"age\",\"race\",\"gender\"]:\n        print(f\" - {col}:\", train_df[col].value_counts().sort_index().to_dict())\n\n    # ======================================================\n    # 4. Cấu hình Image Transforms (Augmentation)\n    # ======================================================\n    IMAGE_SIZE = 112\n\n    # Transform cho tập Train: Tăng cường dữ liệu mạnh để chống overfitting\n    train_tf = T.Compose([\n        T.RandomResizedCrop(IMAGE_SIZE, scale=(0.5, 1.0), ratio=(0.9, 1.1)), # Cắt ngẫu nhiên\n        T.RandomHorizontalFlip(p=0.5),                                       # Lật ngang\n        T.RandomApply([T.ColorJitter(0.8, 0.8, 0.8, 0.2)], p=0.8),           # Thay đổi màu sắc/độ sáng\n        T.RandomGrayscale(p=0.2),                                            # Chuyển xám ngẫu nhiên\n        T.RandomApply([T.GaussianBlur(kernel_size=3, sigma=(0.1, 2))], p=0.5), # Làm mờ\n        T.RandomApply([T.RandomRotation(15)], p=0.3),                        # Xoay nhẹ\n        T.ToTensor(),\n        T.Normalize([0.5], [0.5]) # Chuẩn hóa về [-1, 1]\n    ])\n\n    # Transform cho tập Val: Chỉ resize và chuẩn hóa\n    val_tf = T.Compose([\n        T.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n        T.ToTensor(),\n        T.Normalize([0.5], [0.5]),\n    ])\n\n    # ======================================================\n    # 5. Tạo DataLoader\n    # ======================================================\n    train_ds = MultiTaskFaceDataset(train_df, train_tf)\n    val_ds   = MultiTaskFaceDataset(val_df, val_tf)\n\n    train_loader = DataLoader(train_ds, batch_size=128, shuffle=True, num_workers=4)\n    val_loader   = DataLoader(val_ds, batch_size=128, shuffle=False, num_workers=2)\n\n    print(f\"\\nSẵn sàng huấn luyện: {len(train_ds):,} mẫu train | {len(val_ds):,} mẫu val\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_label_distributions(df, name=\"Train\"):\n    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n    for i, col in enumerate([\"age\", \"race\", \"gender\"]):\n        axes[i].hist(df[col], bins=len(df[col].unique()), rwidth=0.9, color='skyblue', edgecolor='black')\n        axes[i].set_title(f\"{name} {col} distribution\")\n        axes[i].set_xlabel(col)\n        axes[i].set_ylabel(\"count\")\n    plt.tight_layout()\n    plt.show()\n\nplot_label_distributions(train_df, \"Train\")\nplot_label_distributions(val_df, \"Validation\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model structure","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# 1. BASIC BLOCKS\n# ============================================================\n\nclass ConvBNReLU(nn.Module):\n    \"\"\"\n    Khối cơ bản: Convolution -> BatchNorm -> ReLU.\n    Dùng để giảm chiều dữ liệu hoặc xử lý đặc trưng sơ cấp.\n    \"\"\"\n    def __init__(self, in_ch, out_ch, kernel=3, stride=1, padding=1):\n        super().__init__()\n        self.conv = nn.Conv2d(in_ch, out_ch, kernel, stride=stride, padding=padding, bias=False)\n        self.bn = nn.BatchNorm2d(out_ch)\n        self.act = nn.ReLU(inplace=True)\n\n    def forward(self, x):\n        return self.act(self.bn(self.conv(x)))\n\n\nclass SEBlock(nn.Module):\n    \"\"\"\n    Squeeze-and-Excitation Block.\n    Mục đích: Giúp mô hình học được \"kênh nào quan trọng hơn\" (Channel Attention).\n    \"\"\"\n    \n    def __init__(self, ch, reduction=16):\n        super().__init__()\n        hidden = max(8, ch // reduction)\n        self.se = nn.Sequential(\n            nn.AdaptiveAvgPool2d(1),            # Squeeze: Nén không gian (Global Info)\n            nn.Conv2d(ch, hidden, 1, bias=False),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(hidden, ch, 1, bias=False),\n            nn.Sigmoid()                        # Excitation: Tạo trọng số [0, 1]\n        )\n\n    def forward(self, x):\n        return x * self.se(x) # Re-calibrate feature maps\n\n\nclass InvertedResidual(nn.Module):\n    \"\"\"\n    Khối Inverted Residual (MobileNetV2).\n    Cấu trúc: Expand (1x1) -> Depthwise (3x3) -> Squeeze (1x1) -> SE Block (Optional).\n    Giúp tiết kiệm tham số nhưng vẫn giữ được thông tin phong phú nhờ Expand layer.\n    \"\"\"\n    \n    def __init__(self, in_ch, out_ch, stride=1, expand_ratio=6, use_se=True):\n        super().__init__()\n        hidden = in_ch * expand_ratio\n        self.use_res = (stride == 1 and in_ch == out_ch) # Chỉ cộng residual khi kích thước không đổi\n        layers = []\n        \n        # 1. Pointwise Convolution (Expand)\n        if expand_ratio != 1:\n            layers += [\n                nn.Conv2d(in_ch, hidden, 1, bias=False),\n                nn.BatchNorm2d(hidden),\n                nn.ReLU6(inplace=True)\n            ]\n            \n        # 2. Depthwise Convolution (Spatial context)\n        layers += [\n            nn.Conv2d(hidden, hidden, 3, stride, padding=1, groups=hidden, bias=False),\n            nn.BatchNorm2d(hidden),\n            nn.ReLU6(inplace=True)\n        ]\n        \n        self.conv = nn.Sequential(*layers)\n        \n        # 3. Squeeze-and-Excitation (Attention)\n        self.se = SEBlock(hidden) if use_se else nn.Identity()\n        \n        # 4. Pointwise Convolution (Project back to low-dim)\n        self.project = nn.Sequential(\n            nn.Conv2d(hidden, out_ch, 1, bias=False),\n            nn.BatchNorm2d(out_ch)\n        )\n\n    def forward(self, x):\n        out = self.project(self.se(self.conv(x)))\n        return out + x if self.use_res else out\n\n\n# ============================================================\n# 2. MULTI-TASK MODEL\n# ============================================================\n\nclass MultiTaskFaceModel(nn.Module):\n    \"\"\"\n    Mô hình nhận diện khuôn mặt đa nhiệm: Tuổi, Giới tính, Chủng tộc.\n    Đặc điểm:\n    - Backbone ~3.5M tham số (MobileNetV2 variants).\n    - Asymmetric Heads: Các nhánh đầu ra có kích thước khác nhau tùy độ khó của task.\n    - Uncertainty Loss: Tự động cân bằng loss giữa các task.\n    \"\"\"\n    \n    def __init__(self, dropout: float = 0.4):\n        super().__init__()\n        \n        # Width multiplier: Tăng độ rộng mạng lên 1.3 lần để đạt dung lượng ~7.5M params\n        width_mult = 1.3 \n        def C(v): return max(16, int(v * width_mult))\n\n        # --- A. BACKBONE (Trục xương sống - Trích xuất đặc trưng) ---\n        \n        # Stem: Xử lý ảnh đầu vào\n        self.stem = nn.Sequential(\n            ConvBNReLU(3, C(32), stride=2),\n            ConvBNReLU(C(32), C(48)),\n        )\n\n        # Stage 1: Đặc trưng cấp thấp (Low level features - Cạnh, góc)\n        self.stage1 = nn.Sequential(\n            InvertedResidual(C(48), C(64), stride=2, expand_ratio=4),\n            InvertedResidual(C(64), C(64), expand_ratio=4),\n            InvertedResidual(C(64), C(64), expand_ratio=4),\n        )\n\n        # Stage 2: Đặc trưng cấp trung (Mid level features - Mắt, mũi, miệng)\n        self.stage2 = nn.Sequential(\n            InvertedResidual(C(64), C(128), stride=2, expand_ratio=6),\n            InvertedResidual(C(128), C(128), expand_ratio=6),\n            InvertedResidual(C(128), C(128), expand_ratio=6),\n            InvertedResidual(C(128), C(128), expand_ratio=6),\n        )\n\n        # Stage 3: Đặc trưng cấp cao (Semantic features - Lão hóa, cấu trúc mặt)\n        # Tăng expand_ratio để bắt chi tiết tốt hơn cho bài toán Age/Race\n        self.stage3 = nn.Sequential(\n            InvertedResidual(C(128), C(192), stride=2, expand_ratio=6),\n            InvertedResidual(C(192), C(256), expand_ratio=6),\n            InvertedResidual(C(256), C(256), expand_ratio=6), \n        )\n\n        # Final Pointwise & Global Pooling\n        self.final_pw = ConvBNReLU(C(256), C(320), kernel=1, padding=0)\n        \n        # Kết hợp AvgPool (tổng quan) và MaxPool (đặc trưng nổi bật nhất)\n        self.pool = nn.ModuleList([\n            nn.AdaptiveAvgPool2d(1),\n            nn.AdaptiveMaxPool2d(1)\n        ])\n        \n        # Kích thước vector đặc trưng cuối cùng: 320 * width_mult * 2\n        feat_dim = C(320) * 2 \n\n        # --- B. ASYMMETRIC HEADS (Các nhánh đầu ra bất đối xứng) ---\n        # Nguyên lý: Task khó cần mạng sâu/rộng hơn. Task dễ dùng mạng nhỏ hơn.\n        \n        # 1. GENDER HEAD (Priority: Low - Dễ nhất)\n        # Binary classification -> Mạng nông.\n        self.gender_head = nn.Sequential(\n            nn.Linear(feat_dim, 128),\n            nn.BatchNorm1d(128),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.2),\n            nn.Linear(128, 2)\n        )\n\n        # 2. RACE HEAD (Priority: Medium)\n        # 7 classes -> Mạng vừa phải.\n        self.race_head = nn.Sequential(\n            nn.Linear(feat_dim, 256),\n            nn.BatchNorm1d(256),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.3),\n            nn.Linear(256, 128),\n            nn.ReLU(inplace=True),\n            nn.Linear(128, 7)\n        )\n\n        # 3. AGE HEAD (Priority: High - Khó nhất)\n        # Age Estimation cần phân biệt các nếp nhăn/kết cấu nhỏ -> Cần nhiều tham số nhất.\n        self.age_head = nn.Sequential(\n            nn.Linear(feat_dim, 1024),  # Mở rộng chiều (Wide)\n            nn.BatchNorm1d(1024),\n            nn.ReLU(inplace=True),\n            nn.Dropout(dropout),\n            \n            nn.Linear(1024, 512),       # Xử lý sâu (Deep)\n            nn.BatchNorm1d(512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(dropout),\n            \n            nn.Linear(512, 9)           # 9 nhóm tuổi\n        )\n\n        # --- C. UNCERTAINTY WEIGHTS (Trọng số học được) ---\n        # Thay vì gán weight cứng (vd: 1.0, 0.5), để model tự học độ khó của từng task.\n        # log_var càng lớn -> loss task đó càng bị giảm đi.\n        self.log_var_g = nn.Parameter(torch.tensor(0.0))\n        self.log_var_r = nn.Parameter(torch.tensor(0.0))\n        self.log_var_a = nn.Parameter(torch.tensor(0.0))\n\n        self._init_weights()\n\n    def forward(self, x):\n        # Forward qua Backbone\n        x = self.stem(x)\n        x = self.stage1(x)\n        x = self.stage2(x)\n        x = self.stage3(x)\n        x = self.final_pw(x)\n        \n        # Global Pooling & Flatten\n        feats = torch.cat([p(x).flatten(1) for p in self.pool], dim=1)\n        \n        # Trả về dictionary kết quả\n        return {\n            \"gender\": self.gender_head(feats),\n            \"race\": self.race_head(feats),\n            \"age\": self.age_head(feats)\n        }\n\n    def compute_loss(self, outputs: Dict[str, torch.Tensor], labels: Dict[str, torch.Tensor]):\n        \"\"\"\n        Tính toán Multi-task Loss sử dụng Uncertainty Weighting.\n        Formula: Loss = (1 / 2*sigma^2) * Task_Loss + log(sigma)\n        \"\"\"\n        # Label Smoothing giúp model bớt tự tin thái quá, tăng khả năng tổng quát hóa\n        ce_loss = nn.CrossEntropyLoss(label_smoothing=0.1)\n        ce_loss_g = nn.CrossEntropyLoss() # Gender là binary, ít nhiễu nên không cần smoothing nhiều\n\n        # Tính loss từng phần\n        lg = ce_loss_g(outputs[\"gender\"], labels[\"gender\"])\n        lr = ce_loss(outputs[\"race\"], labels[\"race\"])\n        la = ce_loss(outputs[\"age\"], labels[\"age\"])\n\n        # Tính trọng số động (Precision = 1 / variance)\n        prec_g = torch.exp(-self.log_var_g)\n        prec_r = torch.exp(-self.log_var_r)\n        prec_a = torch.exp(-self.log_var_a)\n\n        # Tổng hợp loss\n        loss = (\n            prec_g * lg + 0.5 * self.log_var_g +\n            prec_r * lr + 0.5 * self.log_var_r +\n            prec_a * la + 0.5 * self.log_var_a\n        )\n\n        return loss, {\n            \"total\": loss.item(),\n            \"gender_loss\": lg.item(),\n            \"race_loss\": lr.item(),\n            \"age_loss\": la.item(),\n            # Sigma (độ lệch chuẩn) càng cao nghĩa là task đó model đang thấy \"khó/không chắc chắn\"\n            \"sigma_g\": self.log_var_g.exp().item(), \n            \"sigma_r\": self.log_var_r.exp().item(),\n            \"sigma_a\": self.log_var_a.exp().item(),\n        }\n\n    def _init_weights(self):\n        \"\"\"Khởi tạo trọng số chuẩn Kaiming/Truncated Normal\"\"\"\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n            elif isinstance(m, (nn.BatchNorm2d, nn.BatchNorm1d, nn.GroupNorm)):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                nn.init.trunc_normal_(m.weight, std=0.02)\n                if m.bias is not None:\n                    nn.init.zeros_(m.bias)\n\n# ============================================================\n# 3. KIỂM TRA\n# ============================================================\nif __name__ == \"__main__\":\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    model = MultiTaskFaceModel().to(device)\n    \n    # 1. Kiểm tra số lượng tham số\n    total_params = sum(p.numel() for p in model.parameters())\n    backbone_params = sum(p.numel() for n, p in model.named_parameters() if \"head\" not in n)\n    age_params = sum(p.numel() for p in model.age_head.parameters())\n    \n    print(f\"Total Params: {total_params / 1e6:.2f}M\")\n    print(\"-\" * 40)\n    print(f\"Backbone (Shared): {backbone_params / 1e6:.2f}M\")\n    print(f\"Age Head (Heavy):  {age_params / 1e6:.2f}M\")\n    \n    # 2. Kiểm tra luồng dữ liệu (Forward pass)\n    x = torch.randn(2, 3, 112, 112).to(device) # Batch size 2, ảnh 112x112\n    with torch.no_grad():\n        out = model(x)\n    \n    print(\"-\" * 40)\n    print(\"Output shapes:\")\n    for k, v in out.items():\n        print(f\"  {k}: {v.shape}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train - Evaluate","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# 1. KHẮC PHỤC CÁC LỖI TƯƠNG THÍCH (COMPATIBILITY FIXES)\n# ============================================================\n\n# --- GradScaler ---\n# GradScaler giúp huấn luyện Mixed Precision (FP16) để giảm VRAM và tăng tốc độ.\nuse_cuda = torch.cuda.is_available()\nscaler = GradScaler(enabled=use_cuda)\n\n# --- torch.load với weights_only ---\n# Đăng ký các kiểu dữ liệu an toàn của Numpy để tránh lỗi bảo mật khi load checkpoint cũ.\ntorch.serialization.add_safe_globals([\n    np.core.multiarray.scalar, np.dtype,\n    np.int64, np.int32, np.int16, np.int8,\n    np.uint8, np.float32, np.float64\n])\n\ndef safe_load(path):\n    return torch.load(path, map_location=device, weights_only=False)\n\n# ============================================================\n# 2. THIẾT LẬP MÔI TRƯỜNG (SETUP)\n# ============================================================\n\ndevice = torch.device(\"cuda\" if use_cuda else \"cpu\")\n\ndef set_seed(seed=42):\n    \"\"\"\n    Cố định seed để đảm bảo kết quả có thể tái lập (reproducible).\n    \"\"\"\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    # Tăng tốc độ nếu kích thước mạng không đổi\n    torch.backends.cudnn.benchmark = True\n\n# ============================================================\n# 3. HÀM CHẠY MỘT EPOCH (RUN EPOCH)\n# ============================================================\n\ndef run_epoch(model, loader, optimizer, scheduler, scaler, phase=\"train\"):\n    \"\"\"\n    Chạy 1 vòng lặp qua toàn bộ dữ liệu (train hoặc val).\n    \"\"\"\n    is_train = (phase == \"train\")\n    \n    # Chuyển chế độ model: train (có dropout/BN update) hoặc eval (đóng băng)\n    model.train() if is_train else model.eval()\n    \n    total_loss = 0.0\n    # Dictionary lưu số mẫu dự đoán đúng cho từng task\n    correct = {\"age\": 0, \"race\": 0, \"gender\": 0}\n    total = 0\n    \n    # Thanh tiến trình tqdm\n    pbar = tqdm(loader, desc=f\"{phase.capitalize()} \", leave=False)\n    \n    for imgs, labels in pbar:\n        # Đẩy dữ liệu sang thiết bị (non_blocking giúp tăng tốc data transfer)\n        imgs = imgs.to(device, non_blocking=True)\n        labels = {k: v.to(device, non_blocking=True) for k, v in labels.items()}\n        \n        # Bật tính toán gradient chỉ khi train\n        with torch.set_grad_enabled(is_train):\n            # Mixed Precision Context (tự động chuyển float32 -> float16 ở những chỗ cần thiết)\n            with autocast(enabled=use_cuda):\n                outputs = model(imgs)\n                loss, _ = model.compute_loss(outputs, labels)\n            \n            # --- QUÁ TRÌNH LAN TRUYỀN NGƯỢC (BACKPROPAGATION) ---\n            if is_train:\n                optimizer.zero_grad(set_to_none=True) # Reset gradient sạch sẽ\n                \n                scaler.scale(loss).backward()         # Scale loss để tránh underflow fp16\n                scaler.unscale_(optimizer)            # Unscale trước khi clip gradient\n                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0) # Chặn bùng nổ gradient\n                scaler.step(optimizer)                # Cập nhật trọng số\n                scaler.update()                       # Cập nhật scale factor\n                \n                # Scheduler bước theo batch (nếu dùng CosineAnnealingWarmRestarts)\n                if scheduler and isinstance(scheduler, torch.optim.lr_scheduler.CosineAnnealingWarmRestarts):\n                    scheduler.step()\n            \n            # --- TÍNH TOÁN METRICS ---\n            batch_size = imgs.size(0)\n            total_loss += loss.item() * batch_size\n            total += batch_size\n            \n            # Tính accuracy cho từng task\n            for task in outputs:\n                pred = outputs[task].argmax(dim=1)\n                correct[task] += (pred == labels[task]).sum().item()\n            \n            # Hiển thị loss trên thanh pbar\n            postfix = {\"loss\": f\"{total_loss/total:.4f}\"}\n            if is_train:\n                postfix[\"lr\"] = f\"{optimizer.param_groups[0]['lr']:.2e}\"\n            pbar.set_postfix(postfix)\n    \n    # Scheduler bước theo epoch (nếu không phải WarmRestarts)\n    if is_train and scheduler and not isinstance(scheduler, torch.optim.lr_scheduler.CosineAnnealingWarmRestarts):\n        scheduler.step()\n    \n    # Tổng hợp kết quả\n    acc = {f\"{task}_acc\": v / total for task, v in correct.items()}\n    acc[\"avg_acc\"] = np.mean(list(acc.values()))\n    \n    return {\"loss\": total_loss / total, **acc}\n\n# ============================================================\n# 4. HÀM HUẤN LUYỆN CHÍNH (TRAIN MODEL)\n# ============================================================\n\ndef train_model(model,\n                train_loader,\n                val_loader,\n                num_epochs=20,         \n                checkpoint_path=None,  # Đường dẫn file .pt để resume train\n                save_dir=\"./checkpoints\"):\n    \n    # Tạo thư mục lưu checkpoint\n    os.makedirs(save_dir, exist_ok=True)\n    set_seed(42)\n    model = model.to(device)\n    \n    # Cấu hình Optimizer & Scheduler\n    optimizer = torch.optim.AdamW(model.parameters(), lr=3e-3, weight_decay=1e-2)\n    # CosineAnnealingWarmRestarts giúp model thoát khỏi local minima\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n        optimizer, T_0=10, T_mult=2, eta_min=1e-5\n    )\n    \n    best_val_loss = float('inf')\n    start_epoch = 0\n    \n    # Khởi tạo lịch sử training\n    history = {\n        \"train_loss\": [], \"val_loss\": [],\n        \"val_acc_age\": [], \"val_acc_race\": [],\n        \"val_acc_gender\": [], \"val_acc_avg\": []\n    }\n    \n    # --- LOAD CHECKPOINT (RESUME TRAINING) ---\n    if checkpoint_path and os.path.exists(checkpoint_path):\n        print(f\"Loading checkpoint from: {checkpoint_path}\")\n        try:\n            ckpt = safe_load(checkpoint_path)\n            # Load lại toàn bộ trạng thái\n            model.load_state_dict(ckpt[\"model_state_dict\"])\n            optimizer.load_state_dict(ckpt[\"optimizer_state_dict\"])\n            scheduler.load_state_dict(ckpt[\"scheduler_state_dict\"])\n            scaler.load_state_dict(ckpt[\"scaler_state_dict\"])\n            \n            start_epoch = ckpt.get(\"epoch\", 0) + 1\n            best_val_loss = ckpt.get(\"best_val_loss\", float('inf'))\n            \n            if \"history\" in ckpt:\n                history = ckpt[\"history\"]\n                print(\"Loaded existing history from checkpoint.\")\n            else:\n                print(\"Warning: No 'history' found. Starting fresh logs.\")\n                \n            print(f\"Successfully resumed from epoch {start_epoch}\")\n        except Exception as e:\n            print(f\"Failed to load checkpoint: {e}\")\n            start_epoch = 0\n\n    print(f\"\\nStarting training from epoch {start_epoch + 1} -> {num_epochs}\")\n    \n    # --- TRAINING LOOP ---\n    for epoch in range(start_epoch, num_epochs):\n        print(f\"\\n{'='*60}\")\n        print(f\"EPOCH {epoch+1:03d}/{num_epochs} | LR: {optimizer.param_groups[0]['lr']:.2e}\")\n        print(f\"{'='*60}\")\n        \n        # Chạy train và validation\n        train_metrics = run_epoch(model, train_loader, optimizer, scheduler, scaler, \"train\")\n        val_metrics   = run_epoch(model, val_loader,    None,      None,      scaler, \"val\")\n        \n        # Lưu metrics vào history\n        history[\"train_loss\"].append(train_metrics[\"loss\"])\n        history[\"val_loss\"].append(val_metrics[\"loss\"])\n        history[\"val_acc_age\"].append(val_metrics[\"age_acc\"])\n        history[\"val_acc_race\"].append(val_metrics[\"race_acc\"])\n        history[\"val_acc_gender\"].append(val_metrics[\"gender_acc\"])\n        history[\"val_acc_avg\"].append(val_metrics[\"avg_acc\"])\n        \n        # In kết quả\n        print(f\"TRAIN -> Loss: {train_metrics['loss']:.4f}\")\n        print(f\"VAL   -> Loss: {val_metrics['loss']:.4f} | \"\n              f\"Age: {val_metrics['age_acc']:.3f} Race: {val_metrics['race_acc']:.3f} Gen: {val_metrics['gender_acc']:.3f}\")\n\n        # Chuẩn bị dictionary để lưu\n        save_dict = {\n            \"epoch\": epoch,\n            \"model_state_dict\": model.state_dict(),\n            \"optimizer_state_dict\": optimizer.state_dict(),\n            \"scheduler_state_dict\": scheduler.state_dict(),\n            \"scaler_state_dict\": scaler.state_dict(),\n            \"history\": history,\n            \"best_val_loss\": best_val_loss\n        }\n\n        # Lưu model tốt nhất (Best Model)\n        if val_metrics[\"loss\"] < best_val_loss:\n            best_val_loss = val_metrics[\"loss\"]\n            best_path = os.path.join(save_dir, \"best_model.pt\")\n            save_dict[\"best_val_loss\"] = best_val_loss\n            torch.save(save_dict, best_path)\n            print(f\"NEW BEST MODEL! Saved to {best_path}\")\n\n        # Lưu checkpoint mỗi epoch (Latest Model)\n        if (epoch + 1) % 1 == 0:\n            latest_path = os.path.join(save_dir, f\"epoch_{epoch+1}.pt\")\n            torch.save(save_dict, latest_path)\n            print(f\"Saved checkpoint to {latest_path}\")\n\n    print(f\"\\nTraining finished! Best val loss: {best_val_loss:.4f}\")\n    return history","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if __name__ == \"__main__\":\n\n    model = MultiTaskFaceModel().to(device)\n\n    history=train_model(model,\n                train_loader,\n                val_loader,\n                num_epochs=150,\n                checkpoint_path=\"/kaggle/input/model-gra/pytorch/default/1/best_model.pt\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ckpt = safe_load(\"/kaggle/input/model-gra/pytorch/default/1/best_model.pt\")\nhistory = ckpt[\"history\"]\n\n# Vẽ biểu đồ bằng biến history\nepochs_range = range(1, len(history[\"train_loss\"]) + 1)\n\nplt.figure(figsize=(15, 6))\n\n# Loss Chart\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, history[\"train_loss\"], 'b-o', label='Train Loss')\nplt.plot(epochs_range, history[\"val_loss\"], 'r-o', label='Val Loss')\nplt.title('Training & Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.grid(True)\n\n# Accuracy Chart\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, history[\"val_acc_age\"], label='Age Acc')\nplt.plot(epochs_range, history[\"val_acc_race\"], label='Race Acc')\nplt.plot(epochs_range, history[\"val_acc_gender\"], label='Gender Acc')\nplt.plot(epochs_range, history[\"val_acc_avg\"], 'k--', linewidth=2, label='Avg Acc')\nplt.title('Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.grid(True)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Test predict","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# CẤU HÌNH (CONFIG)\n# ============================================================\nCKPT_PATH = \"/kaggle/input/model-gra/pytorch/default/1/best_model.pt\"\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nIMAGE_SIZE = 112\n\n# Map ngược label (Số) → Tên lớp (String)\ngender_map_inv = {0: \"Male\", 1: \"Female\"}\n\nrace_map_inv = {\n    0: \"White\", 1: \"Black\", 2: \"Latino_Hispanic\",\n    3: \"East Asian\", 4: \"Southeast Asian\", 5: \"Indian\", 6: \"Middle Eastern\"\n}\n\nage_map_inv = {\n    0: \"0-2\", 1: \"3-9\", 2: \"10-19\", 3: \"20-29\",\n    4: \"30-39\", 5: \"40-49\", 6: \"50-59\", 7: \"60-69\", 8: \"70+\"\n}\n\n# ============================================================\n# TIỀN XỬ LÝ ẢNH\n# ============================================================\nval_tf = T.Compose([\n    T.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n    T.ToTensor(),\n    T.Normalize([0.5], [0.5]),\n])\n\ndef process_image(img_path):\n    \"\"\"\n    Đọc ảnh và chuyển thành Tensor cho model.\n    \"\"\"\n    try:\n        img = Image.open(img_path).convert(\"RGB\")\n        return val_tf(img).unsqueeze(0) # [1, C, H, W]\n    except Exception as e:\n        print(f\"Lỗi khi đọc ảnh: {e}\")\n        return None\n\n# ============================================================\n# HÀM DỰ ĐOÁN\n# ============================================================\ndef predict(model, img_tensor):\n    model.eval()\n    with torch.no_grad():\n        img_tensor = img_tensor.to(DEVICE)\n        outputs = model(img_tensor)\n\n        pred_gender = outputs[\"gender\"].argmax(dim=1).item()\n        pred_race   = outputs[\"race\"].argmax(dim=1).item()\n        pred_age    = outputs[\"age\"].argmax(dim=1).item()\n\n    return {\n        \"gender\": gender_map_inv[pred_gender],\n        \"race\":   race_map_inv[pred_race],\n        \"age\":    age_map_inv[pred_age],\n    }\n\n# ============================================================\n# HÀM HIỂN THỊ ẢNH (MỚI THÊM)\n# ============================================================\ndef visualize_result(img_path, result):\n    \"\"\"\n    Hiển thị ảnh gốc và kết quả dự đoán.\n    \"\"\"\n    if not os.path.exists(img_path):\n        return\n\n    # Mở ảnh gốc để hiển thị (không dùng ảnh đã normalize)\n    img = Image.open(img_path).convert(\"RGB\")\n\n    plt.figure(figsize=(6, 6))\n    plt.imshow(img)\n    plt.axis('off') # Tắt trục tọa độ\n\n    # Tạo tiêu đề chứa kết quả\n    title_text = (f\"Gender: {result['gender']} | \"\n                  f\"Age: {result['age']}\\n\"\n                  f\"Race: {result['race']}\")\n    \n    plt.title(title_text, fontsize=12, color='darkblue', fontweight='bold')\n    plt.show()\n\n# ============================================================\n# LOAD MODEL & CHẠY\n# ============================================================\nif __name__ == \"__main__\":\n    # Khởi tạo model\n    model = MultiTaskFaceModel()\n    \n    # Load checkpoint\n    if os.path.exists(CKPT_PATH):\n        try:\n            print(f\"Loading checkpoint: {CKPT_PATH}\")\n            ckpt = torch.load(CKPT_PATH, map_location=DEVICE, weights_only=False)\n            model.load_state_dict(ckpt[\"model_state_dict\"], strict=False)\n            model.to(DEVICE)\n            print(\"Model loaded successfully!\")\n\n            # --- CHẠY THỬ ---\n            img_path = \"/kaggle/input/fairface/FairFace/val/1000.jpg\"\n            \n            if os.path.exists(img_path):\n                # 1. Xử lý ảnh cho model\n                img_tensor = process_image(img_path)\n                \n                if img_tensor is not None:\n                    # 2. Dự đoán\n                    result = predict(model, img_tensor)\n                    \n                    # 3. In kết quả ra màn hình console\n                    print(\"\\n=== KẾT QUẢ DỰ ĐOÁN ===\")\n                    print(result)\n                    \n                    # 4. Hiển thị ảnh minh họa\n                    visualize_result(img_path, result)\n            else:\n                print(f\"Không tìm thấy ảnh tại: {img_path}\")\n                \n        except Exception as e:\n            print(f\"Lỗi khi chạy model: {e}\")\n    else:\n        print(f\"Không tìm thấy checkpoint tại: {CKPT_PATH}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Dowload best_model.zip","metadata":{}},{"cell_type":"code","source":"import os\nimport subprocess\nfrom IPython.display import FileLink, display\n\ndef download_file(path, download_file_name):\n    os.chdir('/kaggle/working/')\n    zip_name = f\"/kaggle/working/{download_file_name}.zip\"\n    command = f\"zip {zip_name} {path} -r\"\n    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n    if result.returncode != 0:\n        print(\"Unable to run zip command!\")\n        print(result.stderr)\n        return\n    display(FileLink(f'{download_file_name}.zip'))\n    \ndownload_file('/kaggle/working/checkpoints/best_model.pt', 'best_model') ","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}