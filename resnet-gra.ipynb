{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceType":"datasetVersion","sourceId":78156,"datasetId":44109},{"sourceType":"datasetVersion","sourceId":1547126,"datasetId":912830},{"sourceType":"modelInstanceVersion","sourceId":620601,"isSourceIdPinned":true}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nfrom glob import glob\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport os\n\n# --- Load dữ liệu gốc ---\ntrain_df = pd.read_csv(\"/kaggle/input/fairface/FairFace/train_labels.csv\")\nval_df   = pd.read_csv(\"/kaggle/input/fairface/FairFace/val_labels.csv\")\n\n# --- Làm sạch & thêm đường dẫn ---\nfor df, subset in [(train_df, \"train\"), (val_df, \"val\")]:\n    df.drop(columns=['service_test'], errors='ignore', inplace=True)\n    df['file'] = df['file'].apply(lambda f: os.path.join(\"/kaggle/input/fairface/FairFace\", f))\n    df['file'] = df['file'].str.replace(f\"{subset}/{subset}\", subset)\n\n# --- Mapping nhãn ---\ngender_map = {'Male': 0, 'Female': 1}\nrace_map = {\n    'White': 0, 'Black': 1, 'Latino_Hispanic': 2,\n    'East Asian': 3, 'Southeast Asian': 4, 'Indian': 5, 'Middle Eastern': 6\n}\nage_map = {\n    '0-2': 0, '3-9': 1, '10-19': 2, '20-29': 3,\n    '30-39': 4, '40-49': 5, '50-59': 6, '60-69': 7, 'more than 70': 8\n}\n\ntrain_df['gender'] = train_df['gender'].map(gender_map)\nval_df['gender']   = val_df['gender'].map(gender_map)\ntrain_df['race']   = train_df['race'].map(race_map)\nval_df['race']     = val_df['race'].map(race_map)\ntrain_df['age']    = train_df['age'].map(age_map)\nval_df['age']      = val_df['age'].map(age_map)\n\n# --- Chia riêng theo task ---\ntrain_gender_df = train_df[['file', 'gender']].copy()\nval_gender_df   = val_df[['file', 'gender']].copy()\n\ntrain_race_df = train_df[['file', 'race']].copy()\nval_race_df   = val_df[['file', 'race']].copy()\n\ntrain_age_df = train_df[['file', 'age']].copy()\nval_age_df   = val_df[['file', 'age']].copy()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nbalanced_data_prep_simple.py\n- Kết hợp FairFace + UTKFace\n- Gộp thêm val để làm train cân bằng hơn (age, race, gender)\n- Dataset an toàn (skip file lỗi)\n- Tự động chia lại val nhỏ sau khi cân bằng\n\"\"\"\n\nimport os, random\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as T\n\n# -------------------------\n# Utils\n# -------------------------\ndef set_seed(seed=42):\n    random.seed(seed); np.random.seed(seed)\n    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n\n# -------------------------\n# Load FairFace\n# -------------------------\ndef load_fairface(base_dir: str):\n    train_df = pd.read_csv(os.path.join(base_dir, \"train_labels.csv\"))\n    val_df = pd.read_csv(os.path.join(base_dir, \"val_labels.csv\"))\n\n    gender_map = {'Male': 0, 'Female': 1}\n    race_map = {\n        'White': 0, 'Black': 1, 'Latino_Hispanic': 2,\n        'East Asian': 3, 'Southeast Asian': 4,\n        'Indian': 5, 'Middle Eastern': 6\n    }\n    age_map = {\n        '0-2': 0, '3-9': 1, '10-19': 2, '20-29': 3, '30-39': 4,\n        '40-49': 5, '50-59': 6, '60-69': 7, 'more than 70': 8\n    }\n\n    for df, subset in [(train_df, \"train\"), (val_df, \"val\")]:\n        df['file'] = df['file'].apply(lambda f: os.path.join(base_dir, f.replace(f\"{subset}/{subset}\", subset)))\n        df['gender'] = df['gender'].map(gender_map)\n        df['race'] = df['race'].map(race_map)\n        df['age'] = df['age'].map(age_map)\n        df.dropna(subset=['gender','race','age'], inplace=True)\n\n    return train_df[['file','age','race','gender']], val_df[['file','age','race','gender']]\n\n# -------------------------\n# Load UTKFace\n# -------------------------\ndef load_utkface(utk_dir: str):\n    recs = []\n    for f in os.listdir(utk_dir):\n        if not f.lower().endswith(('.jpg','.jpeg','.png')): continue\n        parts = f.split('_')\n        if len(parts) < 4: continue\n        try:\n            age, gender, race = int(parts[0]), int(parts[1]), int(parts[2])\n        except: continue\n        if age > 100: continue\n        recs.append([os.path.join(utk_dir, f), age, gender, race])\n    df = pd.DataFrame(recs, columns=['file','age_raw','gender','race'])\n\n    bins = [2,9,19,29,39,49,59,69,200]\n    df['age'] = df['age_raw'].apply(lambda a: next(i for i,b in enumerate(bins) if a <= b))\n    df['race'] = df['race'].map({0:0,1:1,2:3,3:5,4:6}).dropna().astype(int)\n\n    train_df, val_df = train_test_split(df[['file','age','race','gender']],\n                                        test_size=0.2, random_state=42, stratify=df['race'])\n    return train_df.reset_index(drop=True), val_df.reset_index(drop=True)\n\n# -------------------------\n# Dataset\n# -------------------------\nclass MultiTaskFaceDataset(Dataset):\n    def __init__(self, df, transform=None):\n        exists_mask = df['file'].map(os.path.exists)\n        if not exists_mask.all():\n            print(f\"{(~exists_mask).sum()} missing files skipped.\")\n            df = df[exists_mask]\n        self.df = df.reset_index(drop=True)\n        self.transform = transform\n\n    def __len__(self): return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        try: img = Image.open(row['file']).convert('RGB')\n        except: img = Image.new('RGB',(112,112),(0,0,0))\n        if self.transform: img = self.transform(img)\n        labels = {k: torch.tensor(int(row[k]), dtype=torch.long) for k in ['age','race','gender']}\n        return img, labels\n\ndef balance_train_data(train_df, val_df):\n    \"\"\"Cân bằng tuyệt đối cả age, race, gender (undersample & oversample)\"\"\"\n    combined = pd.concat([train_df, val_df], ignore_index=True)\n    print(f\"Trước cân bằng: {len(combined):,} mẫu\")\n\n    # Tạo tất cả tổ hợp nhãn (age, race, gender)\n    combined['combo'] = list(zip(combined['age'], combined['race'], combined['gender']))\n    group_counts = combined['combo'].value_counts()\n    min_count = group_counts.min()\n    max_count = group_counts.max()\n    target = int((min_count + max_count) / 2)  # trung bình, cân bằng hợp lý\n\n    balanced_parts = []\n    for combo, count in group_counts.items():\n        subset = combined[combined['combo'] == combo]\n        if count > target:\n            subset = subset.sample(target, random_state=42)\n        elif count < target:\n            subset = subset.sample(target, replace=True, random_state=42)\n        balanced_parts.append(subset)\n\n    balanced = pd.concat(balanced_parts, ignore_index=True)\n    print(f\"Sau cân bằng: {len(balanced):,} mẫu ({len(group_counts)} tổ hợp nhãn)\")\n\n    # Chia lại val nhỏ (10%)\n    train_df, val_df = train_test_split(balanced, test_size=0.1, random_state=42, stratify=balanced['race'])\n    return train_df.drop(columns=['combo']), val_df.drop(columns=['combo'])\n\n# -------------------------\n# Example\n# -------------------------\nif __name__ == \"__main__\":\n    set_seed(42)\n\n    FAIRFACE_DIR = \"/kaggle/input/fairface/FairFace\"\n    UTK_DIR = \"/kaggle/input/utkface-new/UTKFace\"\n\n    ff_train, ff_val = load_fairface(FAIRFACE_DIR)\n    utk_train, utk_val = load_utkface(UTK_DIR)\n\n    train_df = pd.concat([ff_train, utk_train], ignore_index=True)\n    val_df = pd.concat([ff_val, utk_val], ignore_index=True)\n\n    train_df, val_df = balance_train_data(train_df, val_df)\n\n    print(\"\\nPhân bố train:\")\n    for col in ['age','race','gender']:\n        print(col, train_df[col].value_counts().sort_index().to_dict())\n\n    IMAGE_SIZE = 112\n    mean, std = [0.485,0.456,0.406], [0.229,0.224,0.225]\n    train_tf = T.Compose([\n        T.Resize((IMAGE_SIZE+16, IMAGE_SIZE+16)),\n        T.RandomCrop(IMAGE_SIZE),\n        T.RandomHorizontalFlip(),\n        T.ColorJitter(0.2,0.2,0.15,0.05),\n        T.ToTensor(), T.Normalize(mean,std)\n    ])\n    val_tf = T.Compose([T.Resize((IMAGE_SIZE,IMAGE_SIZE)), T.ToTensor(), T.Normalize(mean,std)])\n\n    train_ds = MultiTaskFaceDataset(train_df, train_tf)\n    val_ds = MultiTaskFaceDataset(val_df, val_tf)\n\n    train_loader = DataLoader(train_ds, batch_size=128, shuffle=True, num_workers=4)\n    val_loader = DataLoader(val_ds, batch_size=128, shuffle=False, num_workers=2)\n\n    print(f\"\\nData ready: {len(train_ds):,} train samples | {len(val_ds):,} val samples\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef plot_label_distributions(df, name=\"Train\"):\n    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n    for i, col in enumerate([\"age\", \"race\", \"gender\"]):\n        axes[i].hist(df[col], bins=len(df[col].unique()), rwidth=0.9, color='skyblue', edgecolor='black')\n        axes[i].set_title(f\"{name} {col} distribution\")\n        axes[i].set_xlabel(col)\n        axes[i].set_ylabel(\"count\")\n    plt.tight_layout()\n    plt.show()\n\nplot_label_distributions(train_df, \"Train\")\nplot_label_distributions(val_df, \"Validation\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# Simplified Multi-task Face Model (CrossEntropyLoss)\n# ============================================================\nimport os, random, math\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torchvision.models as models\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nfrom tqdm.notebook import tqdm\n\n# ============================================================\n# Utils\n# ============================================================\ndef set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.benchmark = True\n\n# ============================================================\n# Model\n# ============================================================\nclass MultiTaskFaceModel(nn.Module):\n    def __init__(self, backbone_type=\"resnet34\", pretrained=True, shared_dim=256):\n        super().__init__()\n        # Backbone\n        if backbone_type == \"resnet34\":\n            base = models.resnet34(weights=\"IMAGENET1K_V1\" if pretrained else None)\n            feat_dim = 512\n        elif backbone_type == \"resnet50\":\n            base = models.resnet50(weights=\"IMAGENET1K_V1\" if pretrained else None)\n            feat_dim = 2048\n        else:\n            raise ValueError(\"Unsupported backbone type\")\n\n        self.backbone = nn.Sequential(*list(base.children())[:-2])\n        self.pool = nn.AdaptiveAvgPool2d(1)\n        self.bn = nn.BatchNorm1d(feat_dim)\n\n        # Shared layer\n        self.shared = nn.Sequential(\n            nn.Linear(feat_dim, shared_dim),\n            nn.BatchNorm1d(shared_dim),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.2)\n        )\n\n        # Heads\n        self.gender_head = nn.Linear(shared_dim, 2)\n        self.race_head   = nn.Linear(shared_dim, 7)\n        self.age_head    = nn.Linear(shared_dim, 9)\n\n    def forward(self, x):\n        x = self.backbone(x)\n        x = self.pool(x).flatten(1)\n        x = self.bn(x)\n        shared = self.shared(x)\n        return {\n            \"gender\": self.gender_head(shared),\n            \"race\": self.race_head(shared),\n            \"age\": self.age_head(shared)\n        }\n\n# ============================================================\n# Training & Validation\n# ============================================================\ndef compute_loss(outputs, targets, criterions):\n    return sum(criterions[t](outputs[t], targets[t]) for t in outputs.keys())\n\ndef run_epoch(model, loader, device, optimizer, phase, criterions, scheduler=None):\n    is_train = (phase == \"train\")\n    model.train(is_train)\n    total_loss, total_samples = 0, 0\n    correct = {\"age\": 0, \"race\": 0, \"gender\": 0}\n\n    if is_train: optimizer.zero_grad(set_to_none=True)\n    pbar = tqdm(loader, desc=f\"{phase}\", leave=False)\n\n    for imgs, labels in pbar:\n        imgs = imgs.to(device)\n        labels = {k: v.to(device) for k, v in labels.items()}\n\n        with torch.autocast(\"cuda\", enabled=device.type == \"cuda\"):\n            outputs = model(imgs)\n            loss = compute_loss(outputs, labels, criterions)\n\n        if is_train:\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n            optimizer.zero_grad(set_to_none=True)\n\n        batch = imgs.size(0)\n        total_loss += loss.item() * batch\n        total_samples += batch\n\n        for t in outputs.keys():\n            pred = outputs[t].argmax(dim=1)\n            correct[t] += (pred == labels[t]).sum().item()\n\n        pbar.set_postfix({\"loss\": f\"{total_loss / total_samples:.4f}\"})\n\n    if is_train and scheduler: scheduler.step()\n\n    metrics = {\n        f\"{phase}_loss\": total_loss / total_samples,\n        f\"{phase}_age_acc\": correct[\"age\"] / total_samples,\n        f\"{phase}_race_acc\": correct[\"race\"] / total_samples,\n        f\"{phase}_gender_acc\": correct[\"gender\"] / total_samples,\n    }\n    metrics[f\"{phase}_avg_acc\"] = (metrics[f\"{phase}_age_acc\"] + metrics[f\"{phase}_race_acc\"] + metrics[f\"{phase}_gender_acc\"]) / 3\n    return metrics\n\n# ============================================================\n# Checkpoint\n# ============================================================\ndef save_checkpoint(path, model, optimizer, epoch, best_val_loss, history):\n    os.makedirs(os.path.dirname(path) or \".\", exist_ok=True)\n    ckpt = {\n        \"epoch\": epoch,\n        \"model_state_dict\": model.state_dict(),\n        \"optimizer_state_dict\": optimizer.state_dict(),\n        \"best_val_loss\": best_val_loss,\n        \"history\": history,\n    }\n    torch.save(ckpt, path)\n    print(f\"Saved checkpoint: {path} | epoch={epoch} | best_val={best_val_loss:.4f}\")\n\ndef load_checkpoint(path, model, optimizer=None, device=\"cpu\"):\n    if not os.path.exists(path):\n        print(\"No checkpoint found.\")\n        return 0, float(\"inf\"), {}\n    ckpt = torch.load(path, map_location=device)\n    model.load_state_dict(ckpt[\"model_state_dict\"])\n    if optimizer: optimizer.load_state_dict(ckpt[\"optimizer_state_dict\"])\n    print(f\"Loaded checkpoint: epoch={ckpt['epoch']} | best_val={ckpt['best_val_loss']:.4f}\")\n    return ckpt[\"epoch\"], ckpt[\"best_val_loss\"], ckpt.get(\"history\", {})\n\n# ============================================================\n# Train\n# ============================================================\ndef train(model, train_loader, val_loader, device,\n          checkpoint_path=\"./checkpoints/multitask_simple.pt\",\n          num_epochs=30, base_lr=3e-4, weight_decay=1e-4):\n\n    set_seed(42)\n    optimizer = torch.optim.AdamW(model.parameters(), lr=base_lr, weight_decay=weight_decay)\n\n    # Simple cosine schedule\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n    criterions = {t: nn.CrossEntropyLoss(label_smoothing=0.05) for t in [\"age\", \"race\", \"gender\"]}\n\n    # start_epoch, best_val_loss, history = load_checkpoint(checkpoint_path, model, optimizer, device)\n    start_epoch, best_val_loss, history = load_checkpoint(\"/kaggle/input/resnet-gra/pytorch/default/1/multitask_simple.pt\", model, optimizer, device)\n\n\n    model.to(device)\n    for epoch in range(start_epoch + 1, num_epochs + 1):\n        print(f\"\\nEpoch {epoch}/{num_epochs} | lr={optimizer.param_groups[0]['lr']:.2e}\")\n        train_m = run_epoch(model, train_loader, device, optimizer, \"train\", criterions, scheduler)\n        val_m = run_epoch(model, val_loader, device, optimizer, \"val\", criterions)\n\n        history[epoch] = {**train_m, **val_m}\n        print(f\"Train loss={train_m['train_loss']:.4f} | Val loss={val_m['val_loss']:.4f}\")\n        print(f\"Val Acc → Age={val_m['val_age_acc']:.3f} Race={val_m['val_race_acc']:.3f} Gender={val_m['val_gender_acc']:.3f}\")\n\n        if val_m[\"val_loss\"] < best_val_loss:\n            best_val_loss = val_m[\"val_loss\"]\n            save_checkpoint(checkpoint_path, model, optimizer, epoch, best_val_loss, history)\n\n    return history\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nif __name__ == \"__main__\":\n    # Paths - update to your dataset locations\n    FAIRFACE_DIR = \"/kaggle/input/fairface/FairFace\"\n    UTK_DIR = \"/kaggle/input/utkface-new/UTKFace\"\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = MultiTaskFaceModel(backbone_type=\"resnet34\").to(device)\n    \n    history = train(\n        model, train_loader, val_loader, device,\n        checkpoint_path=\"./checkpoints/multitask_simple.pt\",\n        num_epochs=100, base_lr=3e-4\n    )\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"kkk","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nimport matplotlib.pyplot as plt\n\nckpt = torch.load(\"/kaggle/working/checkpoints/multitask_simple.pt\", map_location=device)\nhist = ckpt.get(\"history\", {})\n\nepochs = sorted(hist.keys())\ntrain_loss = [hist[e][\"train_loss\"] for e in epochs]\nval_loss = [hist[e][\"val_loss\"] for e in epochs]\n\nplt.plot(epochs, train_loss, label=\"Train Loss\")\nplt.plot(epochs, val_loss, label=\"Val Loss\")\nplt.legend()\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.title(\"Training History\")\nplt.show()\n\nplt.plot(epochs, train_loss, label=\"Train Loss\")\nplt.plot(epochs, val_loss, label=\"Val Loss\")\nplt.legend()\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.title(\"Training History\")\nplt.show()\n\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"kkkkk","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# file: predict_multitask.py\nimport torch\nfrom PIL import Image\nimport torchvision.transforms as T\n\n# ============================================================\n# Cấu hình\n# ============================================================\nCKPT_PATH = \"/kaggle/working/checkpoints/multitask_simple.pt\"\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Map ngược label → tên lớp\ngender_map_inv = {0: \"Male\", 1: \"Female\"}\nrace_map_inv = {\n    0: \"White\", 1: \"Black\", 2: \"Latino_Hispanic\",\n    3: \"East Asian\", 4: \"Southeast Asian\", 5: \"Indian\", 6: \"Middle Eastern\"\n}\nage_map_inv = {\n    0: \"0-2\", 1: \"3-9\", 2: \"10-19\", 3: \"20-29\",\n    4: \"30-39\", 5: \"40-49\", 6: \"50-59\", 7: \"60-69\", 8: \"70+\"\n}\n\n# ============================================================\n# Tiền xử lý ảnh\n# ============================================================\n\ndef load_image(path):\n    img = Image.open(path).convert(\"RGB\")\n    return val_tf(img).unsqueeze(0)  # thêm batch dimension\n\n# ============================================================\n# Hàm dự đoán\n# ============================================================\ndef predict(model, img_tensor):\n    model.eval()\n    with torch.no_grad():\n        img_tensor = img_tensor.to(DEVICE)\n        outputs = model(img_tensor)\n\n        pred_gender = outputs[\"gender\"].argmax(dim=1).item()\n        pred_race   = outputs[\"race\"].argmax(dim=1).item()\n        pred_age    = outputs[\"age\"].argmax(dim=1).item()\n\n    return {\n        \"gender\": gender_map_inv[pred_gender],\n        \"race\": race_map_inv[pred_race],\n        \"age\": age_map_inv[pred_age],\n    }\n\n# ============================================================\n# Load model + checkpoint\n# ============================================================\nmodel = MultiTaskFaceModel()\nckpt = torch.load(CKPT_PATH, map_location=DEVICE)\n\n# nếu bạn lưu EMA shadow hoặc state_dict đầy đủ:\nmodel.load_state_dict(ckpt[\"model_state_dict\"], strict=False)\nmodel.to(DEVICE)\n\n# ============================================================\n# Ví dụ chạy thử\n# ============================================================\nif __name__ == \"__main__\":\n    img_path = \"/kaggle/input/fairface/FairFace/val/1000.jpg\"\n    img_tensor = load_image(img_path)\n    result = predict(model, img_tensor)\n    print(f\"Prediction for {img_path}:\")\n    print(result)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!zip -r /kaggle/working/gra.zip /kaggle/working/checkpoints\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport subprocess\nfrom IPython.display import FileLink, display\n\ndef download_file(path, download_file_name):\n    os.chdir('/kaggle/working/')\n    zip_name = f\"/kaggle/working/{download_file_name}.zip\"\n    command = f\"zip {zip_name} {path} -r\"\n    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n    if result.returncode != 0:\n        print(\"Unable to run zip command!\")\n        print(result.stderr)\n        return\n    display(FileLink(f'{download_file_name}.zip'))\n    \ndownload_file('/kaggle/working/checkpoints', 'checkpoints') ","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}